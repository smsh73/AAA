# AI가 찾은 스타 애널리스트 어워즈 통합 개발계획서

## 1. 개요

### 1.1 프로젝트 목적
애널리스트 리포트 PDF 문서를 정확하게 추출하고, 예측 정보를 데이터베이스에 저장한 후, 멀티 LLM 기반 AI 평가 시스템을 통해 스코어카드를 생성하여 최종 Award를 선정하는 통합 시스템 구축

### 1.2 프로젝트 참여 조직
- **솔트룩스**: 멀티 LLM 통합 시스템 개발
- **이코노미스트**: 어워드 기획 및 리서치 체계 수립
- **KG제로인**: 데이터 제공 및 평가지표 구체화

### 1.3 핵심 요구사항
- **고성능 AI 기반 문서 추출**: 한글/영어 인코딩, 수치 데이터, 해설 데이터, 차트/그래프 이미지 등 복합 레이아웃 PDF 처리
- **다차원 데이터 저장**: 애널리스트별, 기업별, 시장별 예측 정보 구조화 저장
- **평가 기준표 기반 저장**: 현재 평가 기준표에 따른 체계적 데이터 저장
- **스코어카드 생성 및 저장**: 핵심 평가 방식에 따른 스코어카드 DB 저장
- **멀티 LLM 기반 평가**: OpenAI, Claude, Gemini, Perplexity를 통합한 복합 추론 시스템
- **중앙집중형 + 분산협업 하이브리드 구조**: 각 LLM의 특화된 강점을 활용한 협업 시스템

## 2. 시스템 아키텍처

### 2.1 멀티 LLM 아키텍처 구성도

```
┌─────────────────────────────────────────────────────────────┐
│                    서비스 레이어                              │
│  사용자 친화적인 인터페이스로 AI 애널리스트 평가 결과와        │
│  어워드 관리 지원                                             │
└──────────────────────────┬──────────────────────────────────┘
                           │
┌──────────────────────────┴──────────────────────────────────┐
│              AI 에이전트 레이어                              │
│  멀티 LLM 기반 평가·리포트·어워드 전문 에이전트로            │
│  애널리스트 평가 자동화                                       │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐   │
│  │ OpenAI   │  │ Claude   │  │ Gemini   │  │Perplexity│   │
│  │ GPT-4    │  │ 3.5      │  │ Pro      │  │ Online   │   │
│  └──────────┘  └──────────┘  └──────────┘  └──────────┘   │
└──────────────────────────┬──────────────────────────────────┘
                           │
┌──────────────────────────┴──────────────────────────────────┐
│              LLM 통합 레이어                                 │
│  OpenAI(GPT-4)의 추론 능력, Claude의 긴 컨텍스트 처리,      │
│  Gemini의 멀티모달 분석, Perplexity의 실시간 검색 기능 통합 │
└──────────────────────────┬──────────────────────────────────┘
                           │
┌──────────────────────────┴──────────────────────────────────┐
│                    데이터 레이어                              │
│  금융 데이터, 기업 공시, 뉴스 및 KG제로인 API를 통합         │
└──────────────────────────────────────────────────────────────┘
```

### 2.2 멀티 LLM 기반 에이전트 간 상호작용 구조

**협업 구조**: 중앙집중형 + 분산협업 하이브리드 방식

**LLM 간 상호작용 방식**:
- API 기반 표준화된 프롬프트 및 데이터 교환
- 각 LLM이 특화된 영역에서 독립적으로 작업 수행
- ReAct 패턴과 Chain of Thought 방식의 협업 추론
- 중앙 조정 시스템이 작업 할당 및 결과 통합 역할 수행
- 멀티모달 정보 통합: 텍스트, 수치, 차트 통합 분석

**멀티 LLM 활용 이점**:
- 각 모델의 특화된 강점 활용으로 종합적 분석력 향상
- 단일 LLM의 한계 보완 및 편향성 상호 검증
- 실시간 데이터와 과거 데이터의 동적 통합 처리
- 실패 허용 시스템: 단일 모델 장애 시에도 작동 지속
- LLM 간 교차 검증으로 정확도 향상 및 편향성 감소

**정보 흐름 특성**:
- 양방향 순환형 정보 처리
- 피드백 루프: 결과 검증 및 개선

### 2.3 전체 시스템 구조

```
┌─────────────────────────────────────────────────────────────┐
│              애널리스트 리포트 PDF 문서                        │
│    (애널리스트별, 기업별, 시장별 리포트)                        │
└──────────────────────────┬──────────────────────────────────┘
                           │
┌──────────────────────────┴──────────────────────────────────┐
│    Phase 1: 고성능 AI 기반 문서 추출 시스템                    │
│    ┌────────────────────────────────────────────────────┐   │
│    │  Universal Document Scanner                        │   │
│    │  - PDF 레이아웃 분석 (한글/영어 복합)                │   │
│    │  - 페이지 구조 파악                                │   │
│    │  - 요소 영역 식별                                  │   │
│    └────────────────────────────────────────────────────┘   │
│    ┌────────────────────────────────────────────────────┐   │
│    │  Universal Document Parser                         │   │
│    │  - 텍스트 추출 (한글/영어)                          │   │
│    │  - 표 추출 (수치 데이터 포함)                       │   │
│    │  - 이미지 추출 (차트, 그래프)                        │   │
│    │  - OCR (이미지 내 텍스트)                           │   │
│    └────────────────────────────────────────────────────┘   │
│    ┌────────────────────────────────────────────────────┐   │
│    │  VLM 기반 이미지 분석                               │   │
│    │  - 차트/그래프 데이터 추출                          │   │
│    │  - 복잡한 수치 데이터 추출                          │   │
│    │  - 표 이미지 데이터 추출                           │   │
│    └────────────────────────────────────────────────────┘   │
│    ┌────────────────────────────────────────────────────┐   │
│    │  AI 기반 보정 작업                                  │   │
│    │  - 추출 내용 보정 (OpenAI, Claude)                 │   │
│    │  - 수치 데이터 검증                                │   │
│    │  - 구조화된 데이터 변환                            │   │
│    └────────────────────────────────────────────────────┘   │
└──────────────────────────┬──────────────────────────────────┘
                           │
┌──────────────────────────┴──────────────────────────────────┐
│    Phase 2: 예측 정보 추출 및 구조화                           │
│    ┌────────────────────────────────────────────────────┐   │
│    │  예측 정보 추출 (OpenAI Agent)                     │   │
│    │  - 목표주가 추출                                   │   │
│    │  - 실적 예측 추출 (매출액, 영업이익, 순이익)        │   │
│    │  - 투자 논리 추출                                 │   │
│    │  - 위험 요소 추출                                 │   │
│    │  - 예측 기간 추출                                 │   │
│    └────────────────────────────────────────────────────┘   │
│    ┌────────────────────────────────────────────────────┐   │
│    │  메타데이터 추출                                    │   │
│    │  - 애널리스트 정보 (이름, 증권사)                    │   │
│    │  - 기업 정보 (기업명, 종목코드)                      │   │
│    │  - 시장 정보 (산업, 섹터)                           │   │
│    │  - 리포트 발간일                                   │   │
│    └────────────────────────────────────────────────────┘   │
└──────────────────────────┬──────────────────────────────────┘
                           │
┌──────────────────────────┴──────────────────────────────────┐
│    Phase 3: 데이터베이스 저장                                  │
│    ┌────────────────────────────────────────────────────┐   │
│    │  예측 정보 저장                                      │   │
│    │  - 애널리스트별 예측 정보                            │   │
│    │  - 기업별 예측 정보                                 │   │
│    │  - 시장별 예측 정보                                 │   │
│    └────────────────────────────────────────────────────┘   │
│    ┌────────────────────────────────────────────────────┐   │
│    │  원본 문서 저장                                      │   │
│    │  - PDF 파일 저장                                    │   │
│    │  - 추출된 원본 텍스트 저장                           │   │
│    │  - 이미지 파일 저장                                 │   │
│    └────────────────────────────────────────────────────┘   │
└──────────────────────────┬──────────────────────────────────┘
                           │
┌──────────────────────────┴──────────────────────────────────┐
│    Phase 4: AI 기반 평가 시스템                                │
│    ┌────────────────────────────────────────────────────┐   │
│    │  1단계: AI 정량 분석 (40%)                          │   │
│    │  - 목표주가 정확성 (Gemini)                         │   │
│    │  - 실적 추정 정확성 (Gemini)                        │   │
│    │  - 투자 논리 타당성 (Claude)                        │   │
│    │  - 위험 요소 분석 적절성 (Claude)                   │   │
│    │  - 리포트 발간 빈도 (OpenAI)                       │   │
│    └────────────────────────────────────────────────────┘   │
│    ┌────────────────────────────────────────────────────┐   │
│    │  2단계: SNS·시장 반응 분석 (30%)                    │   │
│    │  - SNS 주목도 (Perplexity)                         │   │
│    │  - 언론 빈도 (Perplexity)                          │   │
│    └────────────────────────────────────────────────────┘   │
│    ┌────────────────────────────────────────────────────┘   │
│    │  3단계: 전문가 평가 및 설문 (30%)                    │   │
│    │  - 운용사/리서치센터 설문                            │   │
│    │  - 리테일 투자자 설문                               │   │
│    └────────────────────────────────────────────────────┘   │
└──────────────────────────┬──────────────────────────────────┘
                           │
┌──────────────────────────┴──────────────────────────────────┐
│    Phase 5: 스코어카드 생성 및 저장                            │
│    ┌────────────────────────────────────────────────────┐   │
│    │  스코어카드 생성                                    │   │
│    │  - 각 평가 항목별 점수                              │   │
│    │  - 가중치 적용 최종 점수                            │   │
│    │  - 상세 평가 내역                                  │   │
│    └────────────────────────────────────────────────────┘   │
│    ┌────────────────────────────────────────────────────┐   │
│    │  스코어카드 DB 저장                                 │   │
│    │  - 애널리스트별 스코어카드                          │   │
│    │  - 기업별 스코어카드                                │   │
│    │  - 시장별 스코어카드                                │   │
│    │  - 기간별 스코어카드                                │   │
│    └────────────────────────────────────────────────────┘   │
└──────────────────────────┬──────────────────────────────────┘
                           │
┌──────────────────────────┴──────────────────────────────────┐
│    Phase 6: Award 선정                                        │
│    ┌────────────────────────────────────────────────────┐   │
│    │  랭킹 시스템                                         │   │
│    │  - 애널리스트 랭킹                                  │   │
│    │  - 기업별 랭킹                                      │   │
│    │  - 시장별 랭킹                                      │   │
│    └────────────────────────────────────────────────────┘   │
│    ┌────────────────────────────────────────────────────┐   │
│    │  Award 선정                                         │   │
│    │  - 섹터별 Award                                     │   │
│    │  - 산업별 Award                                     │   │
│    │  - 경력별 Award                                     │   │
│    └────────────────────────────────────────────────────┘   │
└──────────────────────────────────────────────────────────────┘
```

## 3. 데이터 수집 및 소스 관리 시스템

### 3.1 데이터 수집 아키텍처

**목적**: 평가 KPI 수행을 위한 체계적인 데이터 수집 및 소스 관리

**핵심 요구사항**:
- 실적 정보 수집을 위한 Perplexity API 프롬프트 정교화
- 각 KPI에 맞는 여러 개의 Perplexity API용 프롬프트 생성
- 초대용량 프롬프트 인풋/아웃풋 윈도우를 가진 Perplexity API 설계
- 자료수집 → 분석 → 상세평가보고서 생성 → DB저장 파이프라인

### 3.2 데이터 수집 프로세스

```
┌─────────────────────────────────────────────────────────────┐
│    Phase 1: 자료 수집 (Perplexity API)                        │
│    ┌────────────────────────────────────────────────────┐   │
│    │  KPI별 전용 프롬프트 실행                            │   │
│    │  - 목표주가 정확성 데이터 수집                        │   │
│    │  - 실적 추정 정확성 데이터 수집                       │   │
│    │  - SNS 주목도 데이터 수집                            │   │
│    │  - 언론 빈도 데이터 수집                             │   │
│    └────────────────────────────────────────────────────┘   │
└──────────────────────────┬──────────────────────────────────┘
                           │
┌──────────────────────────┴──────────────────────────────────┐
│    Phase 2: 데이터 분석 및 검증                               │
│    ┌────────────────────────────────────────────────────┐   │
│    │  수집된 데이터 검증                                  │   │
│    │  - 출처 신뢰도 검증                                  │   │
│    │  - 데이터 일관성 검증                                │   │
│    │  - 중복 데이터 제거                                  │   │
│    └────────────────────────────────────────────────────┘   │
└──────────────────────────┬──────────────────────────────────┘
                           │
┌──────────────────────────┴──────────────────────────────────┐
│    Phase 3: 상세 평가보고서 생성 (멀티 LLM)                   │
│    ┌────────────────────────────────────────────────────┐   │
│    │  OpenAI: 추론 및 구조화                             │   │
│    │  Claude: 장문 컨텍스트 분석 및 근거 검증             │   │
│    │  Gemini: 수치 데이터 검증 및 차트 분석              │   │
│    │  Perplexity: 추가 검색 및 팩트 체킹                  │   │
│    └────────────────────────────────────────────────────┘   │
└──────────────────────────┬──────────────────────────────────┘
                           │
┌──────────────────────────┴──────────────────────────────────┐
│    Phase 4: DB 저장                                          │
│    ┌────────────────────────────────────────────────────┐   │
│    │  수집된 데이터 저장                                 │   │
│    │  상세 평가보고서 저장                               │   │
│    │  메타데이터 저장                                    │   │
│    └────────────────────────────────────────────────────┘   │
└──────────────────────────────────────────────────────────────┘
```

### 3.3 Perplexity API 프롬프트 설계

#### 3.3.1 초대용량 프롬프트 윈도우 설계

**요구사항**:
- **입력 윈도우**: 최대 1,000,000 토큰 지원 (초대용량)
- **출력 윈도우**: 최대 100,000 토큰 지원 (상세 보고서 생성)
- **스트리밍 응답**: 대용량 출력을 위한 스트리밍 처리
- **청크 처리**: 긴 문서를 청크 단위로 처리

**기술 구현**:
- Perplexity API의 최신 모델 활용 (Sonar Large 등)
- 청크 단위 프롬프트 분할 및 병렬 처리
- 결과 통합 및 중복 제거

#### 3.3.2 KPI별 전용 프롬프트

##### 3.3.2.1 목표주가 정확성 데이터 수집 프롬프트

**프롬프트 구조**:
```
당신은 한국 증권시장의 실적 데이터 수집 전문가입니다.

수집 목표:
- 기업명: {company_name}
- 종목코드: {stock_code}
- 예측 기간: {prediction_period}
- 목표주가: {target_price}

수집해야 할 데이터:
1. 해당 기간의 실제 주가 데이터 (일별, 주별, 월별)
2. 주가 변동 요인 (실적 발표, 뉴스, 시장 상황)
3. 목표주가 달성 여부 및 괴리율
4. 관련 뉴스 및 공시 정보

출력 형식: JSON
{
  "company_name": "기업명",
  "stock_code": "종목코드",
  "prediction_period": "예측 기간",
  "target_price": 목표주가,
  "actual_prices": [
    {
      "date": "날짜",
      "price": 실제주가,
      "deviation_rate": 괴리율
    }
  ],
  "price_factors": ["주가 변동 요인"],
  "news_sources": ["뉴스 출처 URL"],
  "disclosure_sources": ["공시 출처 URL"]
}

중요 사항:
- 모든 데이터는 출처를 명시해야 함
- 한국어와 영어 데이터 모두 수집
- DART, 한국거래소 등 공식 출처 우선
- 최신 데이터 우선
```

##### 3.3.2.2 실적 추정 정확성 데이터 수집 프롬프트

**프롬프트 구조**:
```
당신은 한국 기업의 실적 데이터 수집 전문가입니다.

수집 목표:
- 기업명: {company_name}
- 종목코드: {stock_code}
- 평가 기간: 2025년 1Q, 2Q, 3Q
- 평가 지표: 매출액, 영업이익, 순이익

수집해야 할 데이터:
1. 각 분기별 실제 실적 데이터
   - 매출액 (억원)
   - 영업이익 (억원)
   - 순이익 (억원)
2. 실적 발표일 및 출처
3. 전년 동기 대비 증감률
4. 시장 컨센서스 대비 실적
5. 실적 변동 요인 분석

출력 형식: JSON
{
  "company_name": "기업명",
  "stock_code": "종목코드",
  "quarterly_results": [
    {
      "quarter": "2025Q1",
      "revenue": {
        "actual": 실제매출액,
        "unit": "억원",
        "announcement_date": "발표일",
        "source": "출처",
        "source_url": "출처 URL",
        "yoy_change": 전년동기대비증감률
      },
      "operating_profit": {
        "actual": 실제영업이익,
        "unit": "억원",
        "announcement_date": "발표일",
        "source": "출처",
        "source_url": "출처 URL",
        "yoy_change": 전년동기대비증감률
      },
      "net_profit": {
        "actual": 실제순이익,
        "unit": "억원",
        "announcement_date": "발표일",
        "source": "출처",
        "source_url": "출처 URL",
        "yoy_change": 전년동기대비증감률
      },
      "factors": ["실적 변동 요인"],
      "consensus_comparison": "시장 컨센서스 대비"
    }
  ]
}

중요 사항:
- DART 공시 시스템 우선 수집
- 금융감독원 전자공시시스템 확인
- 공식 재무제표 데이터만 사용
- 모든 수치는 단위 명시 필수
```

##### 3.3.2.3 SNS 주목도 데이터 수집 프롬프트

**프롬프트 구조**:
```
당신은 SNS 데이터 수집 및 분석 전문가입니다.

수집 목표:
- 애널리스트명: {analyst_name}
- 증권사: {securities_firm}
- 리포트 제목: {report_title}
- 리포트 발간일: {report_date}

수집해야 할 데이터:
1. X(Twitter) 언급 데이터
   - 언급 횟수
   - 리트윗/좋아요 수
   - 영향력 있는 계정 언급 여부
2. 블로그 언급 데이터
   - 주요 블로그 플랫폼 언급
   - 조회수 및 댓글 수
3. 인스타그램 언급 데이터
   - 관련 게시물 수
   - 해시태그 사용 빈도
4. 투자자 커뮤니티 반응
   - 네이버 카페, 페이스북 그룹 등

출력 형식: JSON
{
  "analyst_name": "애널리스트명",
  "report_title": "리포트 제목",
  "report_date": "발간일",
  "sns_mentions": {
    "twitter": {
      "mention_count": 언급횟수,
      "retweet_count": 리트윗수,
      "like_count": 좋아요수,
      "influencer_mentions": ["영향력 있는 계정"],
      "viral_index": 바이럴지수
    },
    "blog": {
      "mention_count": 언급횟수,
      "view_count": 조회수,
      "comment_count": 댓글수,
      "platforms": ["플랫폼 목록"]
    },
    "instagram": {
      "post_count": 게시물수,
      "hashtag_count": 해시태그수
    }
  },
  "community_reactions": {
    "naver_cafe": {
      "mention_count": 언급횟수,
      "discussion_count": 토론수
    },
    "facebook_group": {
      "mention_count": 언급횟수
    }
  },
  "sources": ["데이터 출처 URL"]
}

중요 사항:
- 최신 데이터 우선 수집
- 출처 URL 필수 포함
- 감성 분석 포함 (긍정/부정/중립)
```

##### 3.3.2.4 언론 빈도 데이터 수집 프롬프트

**프롬프트 구조**:
```
당신은 언론 데이터 수집 전문가입니다.

수집 목표:
- 애널리스트명: {analyst_name}
- 증권사: {securities_firm}
- 리포트 제목: {report_title}
- 리포트 발간일: {report_date}

수집해야 할 데이터:
1. 주요 언론사 기사 언급
   - 조선일보, 중앙일보, 동아일보, 한겨레, 매일경제, 한국경제 등
   - 언급 횟수
   - 1면 기사 여부
2. 경제 전문지 언급
   - 이코노미스트, 포브스코리아 등
3. 온라인 미디어 언급
   - 네이버 뉴스, 다음 뉴스 등
4. 언론사별 영향력 가중치 적용

출력 형식: JSON
{
  "analyst_name": "애널리스트명",
  "report_title": "리포트 제목",
  "report_date": "발간일",
  "media_mentions": {
    "major_newspapers": {
      "chosun": {
        "mention_count": 언급횟수,
        "front_page": 1면기사여부,
        "articles": ["기사 URL"]
      },
      "joongang": {...},
      "donga": {...}
    },
    "economic_magazines": {
      "economist": {
        "mention_count": 언급횟수,
        "articles": ["기사 URL"]
      }
    },
    "online_media": {
      "naver_news": {
        "mention_count": 언급횟수,
        "articles": ["기사 URL"]
      }
    }
  },
  "total_mention_count": 총언급횟수,
  "influence_score": 영향력점수,
  "sources": ["데이터 출처 URL"]
}

중요 사항:
- 주요 언론사 우선 수집
- 기사 URL 필수 포함
- 발간일 기준 ±7일 범위 수집
```

### 3.4 데이터 소스 관리 시스템

#### 3.4.1 데이터 소스 등록 및 관리

**데이터 소스 테이블**:
```sql
data_sources (데이터 소스)
├── id (PK, UUID)
├── source_name (VARCHAR) - 소스명
├── source_type (VARCHAR) - 소스 타입 (dart, news, sns, etc.)
├── source_url (VARCHAR) - 소스 URL
├── reliability (VARCHAR) - 신뢰도 (high, medium, low)
├── update_frequency (VARCHAR) - 업데이트 빈도
├── last_updated (TIMESTAMP) - 마지막 업데이트
├── is_active (BOOLEAN) - 활성화 여부
└── metadata (JSONB) - 메타데이터
```

#### 3.4.2 데이터 수집 이력 관리

**데이터 수집 이력 테이블**:
```sql
data_collection_logs (데이터 수집 이력)
├── id (PK, UUID)
├── analyst_id (FK -> analysts.id)
├── company_id (FK -> companies.id, nullable)
├── collection_type (VARCHAR) - 수집 타입 (target_price, performance, sns, media)
├── prompt_template_id (VARCHAR) - 사용된 프롬프트 템플릿 ID
├── perplexity_request (JSONB) - Perplexity 요청 내용
├── perplexity_response (JSONB) - Perplexity 응답 내용
├── collected_data (JSONB) - 수집된 데이터
├── status (VARCHAR) - 상태 (success, failed, partial)
├── error_message (TEXT, nullable) - 에러 메시지
├── collection_time (FLOAT) - 수집 소요 시간 (초)
├── token_usage (JSONB) - 토큰 사용량
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)
```

### 3.5 상세 평가보고서 생성 시스템

#### 3.5.1 보고서 생성 프로세스

**멀티 LLM 협업 구조**:
```
1. 수집된 데이터 통합 (Perplexity 결과)
   │
2. OpenAI GPT-4: 추론 및 구조화
   └─> 보고서 구조 설계
   └─> 핵심 인사이트 추출
   │
3. Claude 3.5: 장문 컨텍스트 분석
   └─> 근거 검증
   └─> 상세 분석 작성
   │
4. Gemini Pro: 수치 데이터 검증
   └─> 차트/그래프 생성
   └─> 수치 정확도 검증
   │
5. Perplexity: 추가 검색 및 팩트 체킹
   └─> 보완 정보 수집
   └─> 출처 검증
   │
6. 최종 보고서 통합 및 생성
```

#### 3.5.2 보고서 구조

**상세 평가보고서 템플릿**:
```json
{
  "report_id": "uuid",
  "analyst_id": "uuid",
  "company_id": "uuid",
  "evaluation_period": "2025-Q1",
  "report_date": "2025-01-16",
  "sections": [
    {
      "section_title": "1. 목표주가 정확성 평가",
      "section_type": "target_price_accuracy",
      "content": {
        "summary": "요약",
        "data_collected": {
          "target_price": 목표주가,
          "actual_prices": [...],
          "deviation_analysis": "괴리율 분석"
        },
        "evaluation": {
          "accuracy_score": 정확도점수,
          "reasoning": "평가 근거",
          "sources": ["출처 목록"]
        },
        "charts": [
          {
            "type": "line_chart",
            "title": "목표주가 vs 실제주가 추이",
            "data": [...]
          }
        ]
      },
      "verified_by": ["OpenAI", "Claude", "Gemini"],
      "confidence": 신뢰도
    },
    {
      "section_title": "2. 실적 추정 정확성 평가",
      "section_type": "performance_accuracy",
      "content": {...}
    },
    {
      "section_title": "3. SNS 주목도 평가",
      "section_type": "sns_attention",
      "content": {...}
    },
    {
      "section_title": "4. 언론 빈도 평가",
      "section_type": "media_frequency",
      "content": {...}
    }
  ],
  "overall_evaluation": {
    "final_score": 최종점수,
    "summary": "종합 평가",
    "strengths": ["강점"],
    "weaknesses": ["약점"],
    "recommendations": ["권장사항"]
  },
  "metadata": {
    "data_sources_count": 데이터소스수,
    "verification_status": "verified",
    "report_quality_score": 보고서품질점수
  }
}
```

#### 3.5.3 보고서 생성 프롬프트

**OpenAI GPT-4 프롬프트**:
```
당신은 애널리스트 평가 보고서 작성 전문가입니다.

수집된 데이터:
{collected_data}

작업:
1. 보고서 구조 설계
2. 핵심 인사이트 추출
3. 각 섹션별 요약 작성

출력 형식: JSON (보고서 구조)
```

**Claude 3.5 프롬프트**:
```
당신은 애널리스트 평가 보고서의 상세 분석 작성 전문가입니다.

보고서 구조:
{report_structure}

수집된 데이터:
{collected_data}

작업:
1. 각 섹션별 상세 분석 작성
2. 근거 검증
3. 논리적 일관성 확인

출력 형식: JSON (상세 분석 내용)
```

**Gemini Pro 프롬프트**:
```
당신은 수치 데이터 검증 및 차트 생성 전문가입니다.

수집된 데이터:
{collected_data}

작업:
1. 수치 데이터 정확도 검증
2. 차트/그래프 데이터 생성
3. 통계 분석

출력 형식: JSON (검증 결과 및 차트 데이터)
```

### 3.6 애널리스트 후보군 등록 시스템

#### 3.6.1 Excel 파일 기반 일괄 등록

**Excel 파일 구조**:
- 시트별 섹터 구분 (반도체, 자동차, 방산, 금융)
- 컬럼: 증권사명, 애널리스트명, 부서, 섹터, 이메일 등

**등록 프로세스**:
```
1. Excel 파일 업로드
   │
2. 파일 파싱 및 검증
   └─> 데이터 형식 검증
   └─> 중복 체크
   │
3. 애널리스트 정보 추출
   │
4. 데이터베이스 저장
   └─> analysts 테이블에 저장
   └─> 섹터별 분류
   │
5. 자료수집 시작
   └─> 각 애널리스트별 리포트 수집
   └─> 예측 정보 추출
   └─> 평가 프로세스 시작
```

#### 3.6.2 일괄 등록 API

```
POST /api/analysts/bulk-import
```

**Request**:
- multipart/form-data
- file: Excel 파일

**Response**:
```json
{
  "import_id": "uuid",
  "total_records": 100,
  "success_count": 95,
  "failed_count": 5,
  "failed_records": [
    {
      "row": 10,
      "reason": "중복된 애널리스트"
    }
  ],
  "status": "completed"
}
```

#### 3.6.3 자료수집 자동 시작

**등록 후 자동 프로세스**:
1. 각 애널리스트별 리포트 검색 (Perplexity)
2. 리포트 다운로드 및 파싱
3. 예측 정보 추출
4. 데이터 수집 시작 (각 KPI별)
5. 평가 프로세스 시작

## 4. 데이터베이스 스키마 설계

### 3.1 ERD (Entity Relationship Diagram)

```
analysts (애널리스트)
├── id (PK, UUID)
├── name (VARCHAR)
├── securities_firm (VARCHAR) - 증권사명
├── department - 부서
├── email (VARCHAR, nullable)
├── sector (VARCHAR) - 전문 섹터 (AI, 2차전지, 방산, IPO 등)
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)

companies (기업)
├── id (PK, UUID)
├── name (VARCHAR) - 기업명
├── stock_code (VARCHAR) - 종목코드
├── sector (VARCHAR) - 섹터
├── industry (VARCHAR) - 산업
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)

markets (시장/산업)
├── id (PK, UUID)
├── name (VARCHAR) - 시장/산업명
├── type (VARCHAR) - 시장 타입 (산업, 섹터 등)
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)

reports (리포트)
├── id (PK, UUID)
├── analyst_id (FK -> analysts.id)
├── company_id (FK -> companies.id, nullable) - 기업별 리포트인 경우
├── market_id (FK -> markets.id, nullable) - 시장별 리포트인 경우
├── report_type (VARCHAR) - 리포트 타입 (기업별, 시장별, 산업별 등)
├── title (VARCHAR) - 리포트 제목
├── report_date (DATE) - 리포트 발간일
├── file_path (VARCHAR) - PDF 파일 경로
├── file_size (BIGINT) - 파일 크기
├── total_pages (INTEGER) - 총 페이지 수
├── status (VARCHAR) - 상태 (pending, processing, completed, failed)
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)

extracted_texts (추출된 텍스트)
├── id (PK, UUID)
├── report_id (FK -> reports.id)
├── page_number (INTEGER)
├── text_type (VARCHAR) - 텍스트 타입 (body, header, footer, table, etc.)
├── content (TEXT) - 추출된 텍스트 내용
├── language (VARCHAR) - 언어 (ko, en, mixed)
├── bbox (JSONB) - bounding box 정보
├── confidence (FLOAT) - 추출 신뢰도
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)

extracted_tables (추출된 표)
├── id (PK, UUID)
├── report_id (FK -> reports.id)
├── page_number (INTEGER)
├── table_index (INTEGER) - 페이지 내 표 순서
├── table_data (JSONB) - 표 데이터 (행/열 구조)
├── table_structure (JSONB) - 표 구조 정보
├── bbox (JSONB) - bounding box 정보
├── confidence (FLOAT) - 추출 신뢰도
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)

extracted_images (추출된 이미지)
├── id (PK, UUID)
├── report_id (FK -> reports.id)
├── page_number (INTEGER)
├── image_index (INTEGER) - 페이지 내 이미지 순서
├── image_type (VARCHAR) - 이미지 타입 (chart, graph, table_image, etc.)
├── image_path (VARCHAR) - 이미지 파일 경로
├── ocr_text (TEXT, nullable) - OCR로 추출된 텍스트
├── vlm_analysis (JSONB, nullable) - VLM 분석 결과
├── bbox (JSONB) - bounding box 정보
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)

predictions (예측 정보)
├── id (PK, UUID)
├── report_id (FK -> reports.id)
├── analyst_id (FK -> analysts.id)
├── company_id (FK -> companies.id, nullable)
├── market_id (FK -> markets.id, nullable)
├── prediction_type (VARCHAR) - 예측 타입 (target_price, revenue, operating_profit, net_profit, etc.)
├── predicted_value (DECIMAL) - 예측값
├── unit (VARCHAR) - 단위 (원, 억원, % 등)
├── period (VARCHAR) - 예측 기간 (2025Q1, 2025Q2, 2025Q3, 2025-06 등)
├── reasoning (TEXT) - 예측 근거
├── source_text (TEXT) - 원본 텍스트 (추출된 부분)
├── confidence (FLOAT) - 추출 신뢰도
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)

actual_results (실제 실적)
├── id (PK, UUID)
├── prediction_id (FK -> predictions.id)
├── company_id (FK -> companies.id)
├── actual_value (DECIMAL) - 실제값
├── unit (VARCHAR) - 단위
├── period (VARCHAR) - 기간
├── announcement_date (DATE) - 발표일
├── source (VARCHAR) - 출처 (DART, 금융감독원 등)
├── source_url (VARCHAR) - 출처 URL
├── reliability (VARCHAR) - 신뢰도 (high, medium, low)
├── collected_at (TIMESTAMP)
└── created_at (TIMESTAMP)

investment_logics (투자 논리)
├── id (PK, UUID)
├── report_id (FK -> reports.id)
├── analyst_id (FK -> analysts.id)
├── logic_type (VARCHAR) - 논리 타입 (investment_point, risk_factor, etc.)
├── content (TEXT) - 논리 내용
├── source_text (TEXT) - 원본 텍스트
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)

evaluations (평가 결과)
├── id (PK, UUID)
├── report_id (FK -> reports.id)
├── analyst_id (FK -> analysts.id)
├── company_id (FK -> companies.id, nullable)
├── market_id (FK -> markets.id, nullable)
├── evaluation_period (VARCHAR) - 평가 기간
├── final_score (DECIMAL) - 최종 점수
├── ai_quantitative_score (DECIMAL) - AI 정량 분석 점수
├── sns_market_score (DECIMAL) - SNS·시장 반응 점수
├── expert_survey_score (DECIMAL) - 전문가 평가 및 설문 점수
├── status (VARCHAR) - 상태 (processing, completed, failed)
├── evaluated_at (TIMESTAMP)
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)

evaluation_scores (세부 평가 점수)
├── id (PK, UUID)
├── evaluation_id (FK -> evaluations.id)
├── score_type (VARCHAR) - 점수 타입 (target_price_accuracy, performance_accuracy, etc.)
├── score_value (DECIMAL) - 점수 값
├── weight (DECIMAL) - 가중치
├── details (JSONB) - 상세 정보
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)

scorecards (스코어카드)
├── id (PK, UUID)
├── evaluation_id (FK -> evaluations.id)
├── analyst_id (FK -> analysts.id)
├── company_id (FK -> companies.id, nullable)
├── market_id (FK -> markets.id, nullable)
├── period (VARCHAR) - 기간 (2025-Q1, 2025 등)
├── scorecard_type (VARCHAR) - 스코어카드 타입 (analyst, company, market, period)
├── final_score (DECIMAL) - 최종 점수
├── ranking (INTEGER, nullable) - 랭킹
├── scorecard_data (JSONB) - 스코어카드 상세 데이터
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)

awards (수상 내역)
├── id (PK, UUID)
├── scorecard_id (FK -> scorecards.id)
├── analyst_id (FK -> analysts.id)
├── award_type (VARCHAR) - 수상 타입 (gold, silver, bronze)
├── award_category (VARCHAR) - 수상 카테고리 (AI, 2차전지, 방산, IPO 등)
├── period (VARCHAR) - 기간
├── rank (INTEGER) - 순위
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)

data_sources (데이터 소스)
├── id (PK, UUID)
├── source_name (VARCHAR) - 소스명
├── source_type (VARCHAR) - 소스 타입 (dart, news, sns, etc.)
├── source_url (VARCHAR) - 소스 URL
├── reliability (VARCHAR) - 신뢰도 (high, medium, low)
├── update_frequency (VARCHAR) - 업데이트 빈도
├── last_updated (TIMESTAMP) - 마지막 업데이트
├── is_active (BOOLEAN) - 활성화 여부
├── metadata (JSONB) - 메타데이터
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)

data_collection_logs (데이터 수집 이력)
├── id (PK, UUID)
├── analyst_id (FK -> analysts.id)
├── company_id (FK -> companies.id, nullable)
├── collection_type (VARCHAR) - 수집 타입 (target_price, performance, sns, media)
├── prompt_template_id (VARCHAR) - 사용된 프롬프트 템플릿 ID
├── perplexity_request (JSONB) - Perplexity 요청 내용
├── perplexity_response (JSONB) - Perplexity 응답 내용
├── collected_data (JSONB) - 수집된 데이터
├── status (VARCHAR) - 상태 (success, failed, partial)
├── error_message (TEXT, nullable) - 에러 메시지
├── collection_time (FLOAT) - 수집 소요 시간 (초)
├── token_usage (JSONB) - 토큰 사용량
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)

evaluation_reports (상세 평가보고서)
├── id (PK, UUID)
├── evaluation_id (FK -> evaluations.id)
├── analyst_id (FK -> analysts.id)
├── company_id (FK -> companies.id, nullable)
├── report_type (VARCHAR) - 보고서 타입 (detailed_evaluation)
├── report_structure (JSONB) - 보고서 구조
├── report_content (JSONB) - 보고서 내용
├── report_summary (TEXT) - 보고서 요약
├── data_sources_count (INTEGER) - 데이터 소스 수
├── verification_status (VARCHAR) - 검증 상태
├── report_quality_score (DECIMAL) - 보고서 품질 점수
├── generated_by (JSONB) - 생성에 참여한 LLM 목록
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)

prompt_templates (프롬프트 템플릿)
├── id (PK, UUID)
├── template_name (VARCHAR) - 템플릿명
├── template_type (VARCHAR) - 템플릿 타입 (target_price, performance, sns, media)
├── kpi_type (VARCHAR) - KPI 타입
├── prompt_content (TEXT) - 프롬프트 내용
├── input_schema (JSONB) - 입력 스키마
├── output_schema (JSONB) - 출력 스키마
├── max_input_tokens (INTEGER) - 최대 입력 토큰
├── max_output_tokens (INTEGER) - 최대 출력 토큰
├── version (VARCHAR) - 버전
├── is_active (BOOLEAN) - 활성화 여부
├── created_at (TIMESTAMP)
└── updated_at (TIMESTAMP)
```

### 4.2 인덱스 설계

```sql
-- 성능 최적화를 위한 인덱스
CREATE INDEX idx_reports_analyst_id ON reports(analyst_id);
CREATE INDEX idx_reports_company_id ON reports(company_id);
CREATE INDEX idx_reports_market_id ON reports(market_id);
CREATE INDEX idx_reports_report_date ON reports(report_date);
CREATE INDEX idx_reports_status ON reports(status);

CREATE INDEX idx_predictions_report_id ON predictions(report_id);
CREATE INDEX idx_predictions_analyst_id ON predictions(analyst_id);
CREATE INDEX idx_predictions_company_id ON predictions(company_id);
CREATE INDEX idx_predictions_period ON predictions(period);

CREATE INDEX idx_evaluations_analyst_id ON evaluations(analyst_id);
CREATE INDEX idx_evaluations_company_id ON evaluations(company_id);
CREATE INDEX idx_evaluations_market_id ON evaluations(market_id);
CREATE INDEX idx_evaluations_period ON evaluations(evaluation_period);

CREATE INDEX idx_scorecards_analyst_id ON scorecards(analyst_id);
CREATE INDEX idx_scorecards_company_id ON scorecards(company_id);
CREATE INDEX idx_scorecards_market_id ON scorecards(market_id);
CREATE INDEX idx_scorecards_period ON scorecards(period);
CREATE INDEX idx_scorecards_final_score ON scorecards(final_score DESC);

CREATE INDEX idx_data_collection_logs_analyst_id ON data_collection_logs(analyst_id);
CREATE INDEX idx_data_collection_logs_collection_type ON data_collection_logs(collection_type);
CREATE INDEX idx_data_collection_logs_status ON data_collection_logs(status);
CREATE INDEX idx_data_collection_logs_created_at ON data_collection_logs(created_at);

CREATE INDEX idx_evaluation_reports_evaluation_id ON evaluation_reports(evaluation_id);
CREATE INDEX idx_evaluation_reports_analyst_id ON evaluation_reports(analyst_id);
CREATE INDEX idx_evaluation_reports_company_id ON evaluation_reports(company_id);

CREATE INDEX idx_prompt_templates_template_type ON prompt_templates(template_type);
CREATE INDEX idx_prompt_templates_kpi_type ON prompt_templates(kpi_type);
CREATE INDEX idx_prompt_templates_is_active ON prompt_templates(is_active);
```

## 5. 고성능 AI 기반 문서 추출 시스템

### 5.1 기술 스택

#### 5.1.1 PDF 처리
- **pdfplumber**: 텍스트 및 표 추출
- **PyPDF2**: 기본 PDF 파싱
- **pdfminer.six**: 고급 PDF 파싱
- **camelot**: 표 추출 특화
- **tabula-py**: 표 추출

#### 5.1.2 레이아웃 분석
- **LayoutLM**: 문서 레이아웃 이해
- **Detectron2**: 객체 탐지
- **PaddleOCR**: 레이아웃 분석 모드

#### 5.1.3 OCR
- **Tesseract OCR**: 기본 OCR
- **PaddleOCR**: 한글 OCR 특화
- **EasyOCR**: 다국어 OCR

#### 5.1.4 VLM (Vision Language Model)
- **GPT-4 Vision**: 이미지 분석
- **Claude 3.5 Sonnet with Vision**: 이미지 분석
- **Gemini Pro Vision**: 이미지 분석

#### 5.1.5 AI 서비스
- **OpenAI GPT-4**: 텍스트 보정 및 구조화
- **Claude 3.5 Sonnet**: 텍스트 분석 및 평가
- **Gemini Pro**: 수치 계산 및 데이터 검증
- **Perplexity API**: 외부 데이터 수집

### 4.2 문서 추출 프로세스

#### 4.2.1 Phase 1: Universal Document Scanner

**목적**: PDF 문서의 전체 레이아웃 스캔

**기능**:
1. PDF 파일 로드 및 메타데이터 추출
2. 페이지별 레이아웃 분석
   - 헤더/푸터 영역 식별
   - 본문 영역 식별
   - 컬럼 구조 파악 (1단, 2단, 다단)
3. 요소 영역 식별
   - 텍스트 블록 영역
   - 표 영역
   - 이미지 영역
   - 차트/그래프 영역
   - 수식 영역

**출력**:
```json
{
  "document_metadata": {
    "total_pages": 50,
    "page_width": 595,
    "page_height": 842
  },
  "pages": [
    {
      "page_number": 1,
      "layout": {
        "header": {"bbox": [0, 0, 595, 50]},
        "body": {"bbox": [50, 50, 545, 792]},
        "footer": {"bbox": [0, 792, 595, 842]}
      },
      "elements": [
        {"type": "text_block", "bbox": [50, 100, 545, 200]},
        {"type": "table", "bbox": [50, 250, 545, 450]},
        {"type": "image", "bbox": [50, 500, 545, 700]},
        {"type": "chart", "bbox": [50, 750, 545, 792]}
      ]
    }
  ]
}
```

#### 4.2.2 Phase 2: Universal Document Parser

**목적**: 스캔된 레이아웃 정보를 기반으로 각 요소에서 실제 콘텐츠 추출

**기능**:
1. **텍스트 추출**
   - 한글/영어 혼합 텍스트 추출
   - 제목/부제목 추출
   - 본문 텍스트 추출
   - 리스트 항목 추출

2. **표 추출**
   - 표 구조 파악 (행/열)
   - 표 안의 텍스트 및 수치 데이터 추출
   - 병합된 셀 처리
   - 표 데이터 구조화 (JSON/CSV)

3. **이미지 추출**
   - 원본 해상도 유지
   - 이미지 포맷 (PNG, JPEG)
   - 이미지 메타데이터

4. **OCR 처리**
   - 이미지 내 텍스트 인식 (한글/영어)
   - 텍스트 위치 정보 (bounding box)
   - 신뢰도 점수

5. **차트/그래프 식별**
   - 차트 타입 식별 (막대, 선, 원형 등)
   - 차트 영역 추출
   - 차트 메타데이터

**출력**:
```json
{
  "page_number": 1,
  "text_blocks": [
    {
      "id": "text_1",
      "content": "본문 텍스트 내용...",
      "language": "ko",
      "bbox": [50, 100, 545, 200],
      "confidence": 0.98
    }
  ],
  "tables": [
    {
      "id": "table_1",
      "data": [
        ["헤더1", "헤더2", "헤더3"],
        ["데이터1", "데이터2", "데이터3"]
      ],
      "bbox": [50, 250, 545, 450],
      "confidence": 0.95
    }
  ],
  "images": [
    {
      "id": "image_1",
      "image_path": "/path/to/image_1.png",
      "image_type": "chart",
      "bbox": [50, 500, 545, 700]
    }
  ]
}
```

#### 4.2.3 Phase 3: VLM 기반 이미지 분석

**목적**: 이미지, 차트, 그래프에서 복잡한 수치 데이터 추출

**기능**:
1. **이미지 내 텍스트 추출**
   - 고급 OCR (복잡한 레이아웃)
   - 손글씨 인식
   - 다양한 폰트 인식

2. **차트/그래프 데이터 추출**
   - 막대 그래프: 데이터 값 추출
   - 선 그래프: 데이터 포인트 추출
   - 원형 그래프: 비율 및 값 추출
   - 표 형태 차트: 표 데이터 추출

3. **복잡한 수치 데이터 추출**
   - 표 이미지 데이터 추출
   - 수식 추출
   - 수치 데이터 구조화

**VLM 모델 활용**:
- GPT-4 Vision: 이미지 분석
- Claude 3.5 Sonnet with Vision: 이미지 분석
- Gemini Pro Vision: 이미지 분석

**출력**:
```json
{
  "image_id": "image_1",
  "analysis_results": {
    "chart_type": "bar_chart",
    "data": [
      {"category": "매출액", "value": 1234567, "unit": "억원"},
      {"category": "영업이익", "value": 123456, "unit": "억원"}
    ],
    "metadata": {
      "x_axis": {"label": "항목"},
      "y_axis": {"label": "금액", "unit": "억원"}
    }
  },
  "confidence": 0.92
}
```

#### 4.2.4 Phase 4: AI 기반 보정 작업

**목적**: 추출된 내용의 오류를 수정하고 구조화

**기능**:
1. **텍스트 보정 (OpenAI GPT-4)**
   - OCR 오류 수정
   - 맥락 기반 오류 수정
   - 숫자/날짜 형식 정규화

2. **표 데이터 검증 및 보정 (Gemini Pro)**
   - 표 구조 검증
   - 숫자 형식 정규화
   - 날짜 형식 정규화
   - 단위 통일

3. **구조화된 데이터 변환 (Claude 3.5 Sonnet)**
   - 의미 기반 구조화
   - 제목/부제목 계층 구조
   - 섹션 구분

**출력**:
```json
{
  "corrected_text": "보정된 텍스트...",
  "corrected_tables": [...],
  "structured_data": {
    "sections": [
      {
        "title": "실적 요약",
        "content": "..."
      }
    ]
  }
}
```

### 4.3 예측 정보 추출

#### 4.3.1 목표주가 추출

**담당**: OpenAI Agent

**추출 항목**:
- 목표주가 값
- 목표 기간 (3개월, 6개월, 1년 등)
- 목표주가 설정 근거

**출력**:
```json
{
  "target_prices": [
    {
      "value": 50000,
      "unit": "원",
      "period": "2025-06",
      "reasoning": "목표주가 설정 근거..."
    }
  ]
}
```

#### 4.3.2 실적 예측 추출

**담당**: OpenAI Agent

**추출 항목**:
- 매출액 예측 (1Q, 2Q, 3Q)
- 영업이익 예측 (1Q, 2Q, 3Q)
- 순이익 예측 (1Q, 2Q, 3Q)
- 예측 근거

**출력**:
```json
{
  "performance_predictions": [
    {
      "metric": "매출액",
      "period": "2025Q1",
      "predicted_value": 1000000,
      "unit": "억원",
      "reasoning": "예측 근거..."
    },
    ...
  ]
}
```

#### 4.3.3 투자 논리 추출

**담당**: OpenAI Agent

**추출 항목**:
- 투자 포인트
- 투자 근거
- 성장 동력
- 경쟁 우위

**출력**:
```json
{
  "investment_logics": [
    {
      "type": "investment_point",
      "content": "투자 포인트 내용...",
      "reasoning": "근거..."
    }
  ]
}
```

#### 4.3.4 위험 요소 추출

**담당**: OpenAI Agent

**추출 항목**:
- 위험 요소 목록
- 위험 요소 설명
- 위험 대응 방안

**출력**:
```json
{
  "risk_factors": [
    {
      "risk_type": "시장 위험",
      "description": "위험 요소 설명...",
      "mitigation": "대응 방안..."
    }
  ]
}
```

## 6. 데이터베이스 저장 프로세스

### 5.1 리포트 메타데이터 저장

```python
# 리포트 기본 정보 저장
report = Report(
    analyst_id=analyst.id,
    company_id=company.id if company else None,
    market_id=market.id if market else None,
    report_type="company" if company else "market",
    title=extracted_metadata["title"],
    report_date=extracted_metadata["report_date"],
    file_path=pdf_file_path,
    file_size=file_size,
    total_pages=total_pages,
    status="processing"
)
db.session.add(report)
db.session.commit()
```

### 5.2 추출된 콘텐츠 저장

```python
# 추출된 텍스트 저장
for text_block in extracted_texts:
    extracted_text = ExtractedText(
        report_id=report.id,
        page_number=text_block["page_number"],
        text_type=text_block["type"],
        content=text_block["content"],
        language=text_block["language"],
        bbox=text_block["bbox"],
        confidence=text_block["confidence"]
    )
    db.session.add(extracted_text)

# 추출된 표 저장
for table in extracted_tables:
    extracted_table = ExtractedTable(
        report_id=report.id,
        page_number=table["page_number"],
        table_index=table["index"],
        table_data=table["data"],
        table_structure=table["structure"],
        bbox=table["bbox"],
        confidence=table["confidence"]
    )
    db.session.add(extracted_table)

# 추출된 이미지 저장
for image in extracted_images:
    extracted_image = ExtractedImage(
        report_id=report.id,
        page_number=image["page_number"],
        image_index=image["index"],
        image_type=image["type"],
        image_path=image["path"],
        ocr_text=image.get("ocr_text"),
        vlm_analysis=image.get("vlm_analysis"),
        bbox=image["bbox"]
    )
    db.session.add(extracted_image)

db.session.commit()
```

### 5.3 예측 정보 저장

```python
# 목표주가 저장
for target_price in extracted_predictions["target_prices"]:
    prediction = Prediction(
        report_id=report.id,
        analyst_id=analyst.id,
        company_id=company.id if company else None,
        market_id=market.id if market else None,
        prediction_type="target_price",
        predicted_value=target_price["value"],
        unit=target_price["unit"],
        period=target_price["period"],
        reasoning=target_price["reasoning"],
        source_text=target_price["source_text"],
        confidence=target_price["confidence"]
    )
    db.session.add(prediction)

# 실적 예측 저장
for perf_pred in extracted_predictions["performance_predictions"]:
    prediction = Prediction(
        report_id=report.id,
        analyst_id=analyst.id,
        company_id=company.id if company else None,
        market_id=market.id if market else None,
        prediction_type=perf_pred["metric"],
        predicted_value=perf_pred["predicted_value"],
        unit=perf_pred["unit"],
        period=perf_pred["period"],
        reasoning=perf_pred["reasoning"],
        source_text=perf_pred["source_text"],
        confidence=perf_pred["confidence"]
    )
    db.session.add(prediction)

db.session.commit()
```

### 5.4 투자 논리 및 위험 요소 저장

```python
# 투자 논리 저장
for logic in extracted_investment_logics:
    investment_logic = InvestmentLogic(
        report_id=report.id,
        analyst_id=analyst.id,
        logic_type=logic["type"],
        content=logic["content"],
        source_text=logic["source_text"]
    )
    db.session.add(investment_logic)

db.session.commit()
```

## 7. 평가 시스템 및 스코어카드 생성

### 6.1 평가 프로세스

#### 6.1.1 1단계: AI 정량 분석 (40%)

**평가 항목**:
1. 목표주가 정확성 (25%)
2. 실적 추정 정확성 (30%)
3. 투자 논리 타당성 (15%)
4. 위험 요소 분석 적절성 (10%)
5. 리포트 발간 빈도 (5%)

**구현**: `AI_평가_기능_구현_기획서.md` 참조

#### 6.1.2 2단계: SNS·시장 반응 분석 (30%)

**평가 항목**:
1. SNS 주목도 평가 (10%)
2. 언론 빈도 평가 (5%)

#### 6.1.3 3단계: 전문가 평가 및 설문 (30%)

**평가 항목**:
1. 운용사/리서치센터 설문
2. 리테일 투자자 설문

### 6.2 스코어카드 생성 및 저장

```python
# 평가 결과 저장
evaluation = Evaluation(
    report_id=report.id,
    analyst_id=analyst.id,
    company_id=company.id if company else None,
    market_id=market.id if market else None,
    evaluation_period="2025-Q1",
    final_score=final_score,
    ai_quantitative_score=ai_quantitative_score,
    sns_market_score=sns_market_score,
    expert_survey_score=expert_survey_score,
    status="completed",
    evaluated_at=datetime.now()
)
db.session.add(evaluation)
db.session.commit()

# 세부 평가 점수 저장
for score_detail in score_details:
    evaluation_score = EvaluationScore(
        evaluation_id=evaluation.id,
        score_type=score_detail["type"],
        score_value=score_detail["value"],
        weight=score_detail["weight"],
        details=score_detail["details"]
    )
    db.session.add(evaluation_score)

# 스코어카드 생성 및 저장
scorecard = Scorecard(
    evaluation_id=evaluation.id,
    analyst_id=analyst.id,
    company_id=company.id if company else None,
    market_id=market.id if market else None,
    period="2025-Q1",
    scorecard_type="analyst",
    final_score=final_score,
    ranking=None,  # 랭킹은 별도 계산
    scorecard_data={
        "scores": score_details,
        "summary": evaluation_summary
    }
)
db.session.add(scorecard)
db.session.commit()
```

## 8. 멀티 LLM 기반 복합 추론 알고리즘

### 7.1 멀티 LLM 협업 추론

**목적**: OpenAI, Claude, Gemini, Perplexity 각 모델의 강점을 결합하여 시너지 효과를 극대화하는 복합 추론 시스템 구현

**각 LLM의 특화 기능**:
- **OpenAI (GPT-4)**: 핵심 추론 및 분석력 담당, 재무제표 해석 및 투자 전략 개발
- **Claude (Claude 3.5)**: 장문 컨텍스트 처리, 복잡한 재무보고서 및 연간 공시자료 종합분석
- **Gemini (Gemini Pro)**: 멀티모달 데이터 처리, 차트/그래프 분석 및 시각자료 기반 예측
- **Perplexity**: 실시간 정보 검색, 최신 시장 데이터 및 뉴스 반영 분석

### 7.2 다단계 크로스체킹 프로세스

**목적**: 각 LLM의 분석 결과를 교차검증하여 정확도와 신뢰도를 향상시키는 자기검증 알고리즘 적용

**프로세스**:
1. 각 LLM이 독립적으로 분석 수행
2. 결과 비교 및 일관성 검증
3. 불일치 시 재분석 요청
4. 최종 앙상블 결과 생성

### 7.3 시나리오 기반 복합 추론

**목적**: 다양한 경제 시나리오를 생성하고 각 LLM이 시나리오별 영향 분석 후 종합적 투자 전략 도출

**프로세스**:
1. 시나리오 생성 (OpenAI)
2. 각 시나리오별 영향 분석 (각 LLM)
3. 시나리오별 확률 및 영향도 평가
4. 종합 투자 전략 도출

### 7.4 확률/리스크 평가 시스템

**목적**: 각 투자전략에 대한 성공확률, 위험도, 기대수익률을 AI 모델 앙상블 방식으로 계산하여 객관적 평가

**평가 항목**:
- 성공 확률
- 위험도
- 기대 수익률
- 최악 시나리오 분석

## 9. 멀티 LLM 기반 UI/UX 설계

### 8.1 멀티 LLM 통합 대시보드

**기능**:
- OpenAI, Claude, Gemini, Perplexity 각 모델의 분석 결과를 한눈에 비교할 수 있는 통합 인터페이스
- 모델별 장단점 비교 시각화
- 모델별 신뢰도 점수 표시

### 8.2 사용자 역할별 맞춤형 인터페이스

**사용자 유형**:
- 펀드매니저: 포트폴리오 최적화 중심
- 기관투자자: 리스크 관리 중심
- 증권사: 리포트 품질 평가 중심
- 일반 투자자: 이해하기 쉬운 시각화 중심

### 8.3 평가 결과 시각화

**시각화 항목**:
- GPT-4의 추론 과정
- Claude의 장문 분석
- Gemini의 차트 해석
- Perplexity의 검색 결과

### 8.4 인터랙티브 멀티모달 리포트

**기능**:
- 다양한 LLM의 분석 결과를 통합하여 심층적으로 살펴볼 수 있는 대화형 리포트 시스템
- 모델 간 교차 검증 기능 제공
- 실시간 결과 업데이트

### 8.5 통합 사용자 경험

**요구사항**:
- PC, 태블릿, 모바일 등 다양한 디바이스에서 멀티 LLM 기반 분석 결과에 접근 가능
- 반응형 디자인 및 일관된 사용자 경험 제공

### 8.6 모델 선택 및 가중치 조정 기능

**기능**:
- 사용자가 각 LLM 모델(OpenAI, Claude, Gemini, Perplexity)의 분석 결과 반영 비율을 조정할 수 있는 직관적인 인터페이스 제공
- 실시간 가중치 조정 및 결과 재계산

## 10. 개발 단계

### Phase 1: 문서 추출 시스템 구축 (6주)

**목표**: 고성능 AI 기반 문서 추출 시스템 구축

**작업 내용**:
1. PDF 처리 라이브러리 통합
2. 레이아웃 분석 시스템 구축
3. OCR 시스템 구축
4. VLM 기반 이미지 분석 시스템 구축
5. AI 기반 보정 시스템 구축

**산출물**:
- 문서 추출 파이프라인
- 추출 결과 검증 시스템

### Phase 2: 데이터베이스 설계 및 구축 (2주)

**목표**: 데이터베이스 스키마 설계 및 구축

**작업 내용**:
1. ERD 설계
2. 데이터베이스 스키마 생성
3. 인덱스 설계 및 생성
4. 마이그레이션 스크립트 작성

**산출물**:
- 데이터베이스 스키마
- 마이그레이션 스크립트

### Phase 3: 데이터 수집 및 소스 관리 시스템 (6주)

**목표**: 평가 KPI 수행을 위한 체계적인 데이터 수집 시스템 구축

**작업 내용**:
1. Perplexity API 통합 및 초대용량 프롬프트 윈도우 구현
2. KPI별 전용 프롬프트 템플릿 개발
   - 목표주가 정확성 데이터 수집 프롬프트
   - 실적 추정 정확성 데이터 수집 프롬프트
   - SNS 주목도 데이터 수집 프롬프트
   - 언론 빈도 데이터 수집 프롬프트
3. 데이터 소스 관리 시스템 구축
4. 데이터 수집 이력 관리 시스템
5. Excel 파일 기반 애널리스트 일괄 등록 시스템
6. 자료수집 자동 시작 프로세스

**산출물**:
- Perplexity API 통합 모듈
- KPI별 프롬프트 템플릿
- 데이터 소스 관리 시스템
- 일괄 등록 시스템

### Phase 4: 예측 정보 추출 시스템 (4주)

**목표**: 리포트에서 예측 정보 추출

**작업 내용**:
1. OpenAI Agent를 활용한 예측 정보 추출
2. 목표주가 추출
3. 실적 예측 추출
4. 투자 논리 추출
5. 위험 요소 추출

**산출물**:
- 예측 정보 추출 모듈
- 추출 결과 검증 시스템

### Phase 5: 상세 평가보고서 생성 시스템 (4주)

**목표**: 멀티 LLM 기반 상세 평가보고서 생성 시스템 구축

**작업 내용**:
1. 멀티 LLM 협업 보고서 생성 파이프라인
2. OpenAI GPT-4: 추론 및 구조화
3. Claude 3.5: 장문 컨텍스트 분석 및 근거 검증
4. Gemini Pro: 수치 데이터 검증 및 차트 생성
5. Perplexity: 추가 검색 및 팩트 체킹
6. 보고서 통합 및 품질 검증
7. 보고서 DB 저장 시스템

**산출물**:
- 멀티 LLM 협업 보고서 생성 시스템
- 보고서 템플릿
- 보고서 품질 검증 시스템

### Phase 6: 데이터 저장 시스템 (2주)

**목표**: 추출된 데이터를 데이터베이스에 저장

**작업 내용**:
1. 리포트 메타데이터 저장
2. 추출된 콘텐츠 저장
3. 예측 정보 저장
4. 투자 논리 및 위험 요소 저장

**산출물**:
- 데이터 저장 모듈
- 데이터 검증 시스템

### Phase 7: AI 평가 시스템 (6주)

**목표**: AI 기반 평가 시스템 구축

**작업 내용**:
1. 1단계: AI 정량 분석 시스템
2. 2단계: SNS·시장 반응 분석 시스템
3. 3단계: 전문가 평가 및 설문 시스템
4. 평가 점수 계산 및 통합

**산출물**:
- AI 평가 시스템
- 평가 결과 검증 시스템

### Phase 8: 스코어카드 생성 및 Award 선정 (2주)

**목표**: 스코어카드 생성 및 Award 선정 시스템

**작업 내용**:
1. 스코어카드 생성 로직
2. 랭킹 시스템
3. Award 선정 로직
4. 결과 시각화

**산출물**:
- 스코어카드 생성 시스템
- Award 선정 시스템

### Phase 9: 통합 테스트 및 최적화 (4주)

**목표**: 전체 시스템 통합 및 최적화

**작업 내용**:
1. 통합 테스트
2. 성능 최적화
3. 에러 처리 개선
4. 사용자 피드백 반영

**산출물**:
- 통합된 시스템
- 테스트 보고서
- 성능 최적화 보고서

**총 개발 기간: 약 32주 (8개월)**

**개발 단계별 기간**:
- Phase 1: 문서 추출 시스템 구축 (6주)
- Phase 2: 데이터베이스 설계 및 구축 (2주)
- Phase 3: 데이터 수집 및 소스 관리 시스템 (6주) ⭐ 신규
- Phase 4: 예측 정보 추출 시스템 (4주)
- Phase 5: 상세 평가보고서 생성 시스템 (4주) ⭐ 신규
- Phase 6: 데이터 저장 시스템 (2주)
- Phase 7: AI 평가 시스템 (6주)
- Phase 8: 스코어카드 생성 및 Award 선정 (2주)
- Phase 9: 통합 테스트 및 최적화 (4주)

### 10.1 멀티 LLM 개발 일정표 (참고)

#### 10.1.1 기획 및 착수단계 (2025년 하반기)
- **9월**: 멀티 LLM 프로젝트 킥오프
- **10월**: OpenAI, Claude, Gemini, Perplexity API 연동 설계
- **12월**: 통합 프로토타입 개발 완료

#### 10.1.2 개발 및 검증단계 (2026년 상반기)
- **1-2월**: 멀티 LLM 조정 시스템 개발 및 내부 테스트
- **3월**: API 성능 및 비용 최적화
- **5-6월**: 멀티 LLM 통합 추론 엔진 고도화
- **7월**: 대규모 벤치마크 테스트

#### 10.1.3 서비스 론칭 (2026년 하반기)
- **9월**: 멀티 LLM 기반 애널리스트 평가 시스템 베타 오픈
- **10-11월**: LLM별 특화기능 및 성능 최적화
- **12월**: 정식 서비스 론칭 및 첫 어워드 시상

#### 10.1.4 주요 마일스톤
- **2025년 12월**: 4개 LLM 통합 프로토타입 완성
- **2026년 3월**: LLM 간 추론 조율 시스템 구축
- **2026년 7월**: LLM 성능 비교 분석 완료
- **2026년 12월**: 첫 멀티 LLM 기반 어워드 시상

## 11. 투자 비용 계획

### 11.1 초기 투자 비용

#### 11.1.1 개발 인력 및 인프라 비용
- **총 4억원**
- AI 엔지니어 4명
- 데이터 사이언티스트 2명
- 최소 인프라 구성

#### 11.1.2 데이터 구매 및 외부 비용
- **총 2억원**
- 금융 데이터 API
- KG제로인 데이터 선별적 구매

#### 11.1.3 멀티 LLM API 사용료
- **총 1.8억원**
- OpenAI: 6천만원
- Claude: 5천만원
- Gemini: 4천만원
- Perplexity: 3천만원

#### 11.1.4 멀티 LLM 통합 개발 비용
- **총 1.2억원**
- API 연동
- 통합 인터페이스
- 프롬프트 엔지니어링
- 데이터 처리 파이프라인

#### 11.1.5 총 초기 투자 비용
- **총 9.5억원** (10억원 이내 예산 준수)

### 11.2 연간 운영 및 고도화 비용
- **총 2.5억원/년**
- 필수 업데이트
- 모델 파인튜닝
- API 버전 호환성 유지

### 11.3 예상 ROI 및 회수 계획
- **1.5년 내 투자금 회수 목표**
- 어워드 브랜드 가치
- 기술 라이센싱 통한 추가 수익 창출

## 12. 기술적 고려사항

### 12.1 한글/영어 혼합 처리
- 한글 인코딩 (UTF-8) 지원
- 영어 인코딩 지원
- 혼합 텍스트 처리
- 폰트 인식 및 처리

### 12.2 수치 데이터 처리
- 숫자 형식 정규화
- 단위 통일
- 날짜 형식 정규화
- 수식 계산

### 12.3 차트/그래프 이미지 처리
- 다양한 차트 타입 인식
- 데이터 추출 정확도 향상
- VLM 모델 앙상블 활용

### 12.4 성능 최적화
- 병렬 처리 (페이지별, 이미지별)
- 캐싱 전략
- 배치 처리
- 비동기 처리

### 12.5 확장성
- 수평 확장 가능한 구조
- 마이크로서비스 아키텍처 고려
- 큐 시스템 활용

## 13. 개발 프롬프트 시스템 개요

### 13.1 모노레포 구조

**리포지토리 구조**: 모노레포 (Turborepo 또는 pnpm workspace)

**패키지 구성**:
- `apps/web` - Next.js + TypeScript + Tailwind
- `apps/api` - FastAPI + uvicorn
- `packages/shared` - TS/Python 공용 스키마
- `apps/worker` - Celery 백그라운드 작업
- `infra` - Docker Compose, IaC 템플릿

**핵심 모듈**:
- 포털(리서치/기업/어워드/평가)
- 에이전트 콘솔
- 데이터 파이프라인
- 멀티 LLM 오케스트레이션

### 13.2 아키텍처 원칙

#### 13.2.1 디자인 원칙
- **전면 흑백**: 컬러 사용 금지, 모든 UI 요소는 흑백으로만 구성
- **직선 구조**: 모든 도형과 다이어그램은 사각형과 직선만 사용 (곡선 금지)
- **반응형**: 모바일부터 데스크톱까지 모든 화면 크기 지원
- **접근성**: ARIA 속성 적용, 키보드 내비게이션 지원
- **다국어**: 한글 UI 기본, 영문 폴백 지원

#### 13.2.2 코딩 규칙
- **린트/포맷**: ESLint, Prettier, ruff, black 적용
- **테스트**: pytest, vitest로 단위/통합 테스트 구현
- **컨벤션**: conventional commits, GitHub Flow 전략

### 13.3 기술 스택 구성

#### 13.3.1 Frontend
- Next.js 14, TypeScript, TailwindCSS, React Query, Zod

#### 13.3.2 Backend
- FastAPI, SQLModel/SQLAlchemy, PostgreSQL, Redis, Celery

#### 13.3.3 AI/ML
- OpenAI API, Anthropic API, Google Gemini API, Perplexity API, FAISS/pgvector

#### 13.3.4 DevOps
- Docker, Kubernetes, OpenTelemetry, Prometheus, Loki

### 13.4 보안 및 비용 관리

#### 13.4.1 환경 분리
- `.env` 파일로 개발/스테이징/프로덕션 환경 분리

#### 13.4.2 비용 상한
- LLM API 사용량 쿼터 및 예산 상한 설정

#### 13.4.3 민감정보 처리
- 기업 재무, 애널리스트 개인정보 마스킹 처리

#### 13.4.4 인증/권한
- JWT + RBAC 기반 세분화된 접근 제어

#### 13.4.5 모델 요청 보안
- 프롬프트 인젝션 방지, 입력 샌드박싱
- 출력 필터링, 저작권 검증, 인용 확인

## 14. 프론트엔드 포털 설계

### 14.1 주요 화면

#### 14.1.1 대시보드 (`/dashboard`)
- 지표 대시보드
- 알림 센터
- 작업큐 상태
- 최근 활동 로그

#### 14.1.2 애널리스트 목록/프로필 (`/analysts`, `/analysts/[id]`)
- 성과 지표
- 리포트 아카이브
- 추천 히스토리
- 정확도 시각화

#### 14.1.3 리포트 (`/reports`, `/reports/[id]`)
- 목록, 상세 보기, 미리보기
- PDF 다운로드
- 섹션별 분석

#### 14.1.4 기업 DB (`/companies`, `/companies/[ticker]`)
- 기업개요
- 재무정보
- 이벤트 타임라인
- 애널리스트 커버리지

#### 14.1.5 평가/어워드 현황 (`/awards`, `/scores`)
- 스코어보드
- 평가기준 설정
- 수상 히스토리
- 카테고리별 순위

#### 14.1.6 에이전트 콘솔 (`/agents`, `/agents/[id]/logs`)
- 에이전트 상태 모니터링
- 작업 실행/로그
- 설정 관리

### 14.2 공통 컴포넌트

#### 14.2.1 테이블
- 가상 스크롤
- 정렬/필터/컬럼 토글 기능
- CSV/XLSX 내보내기
- 페이징: 번호 기반, 무한 스크롤 옵션, 페이지당 항목 수 설정

**테이블 스타일**:
- 흑백 컬러 스키마: 컬러 사용 금지
- 셀 테두리: 1px 실선
- 행간(compact): 셀 패딩 최소화
- 헤더 구분: 굵은 테두리로 구분
- 정렬: 숫자 우측, 텍스트 좌측 정렬
- 행 호버: 배경색 약간 어둡게 변경
- 선택된 행: 테두리 강조

#### 14.2.2 검색바
- 자동완성
- 필터 드롭다운
- 최근 검색어 저장

#### 14.2.3 모달
- 직사각형 형태
- 키보드 접근성
- 뒤로가기 연동

#### 14.2.4 토스트
- 상단 또는 우측 하단 알림
- 자동 소멸
- 상태별 아이콘

#### 14.2.5 Stepper
- 직선형 단계 표시
- 현재/완료 상태 구분

#### 14.2.6 아이콘
- 단색, 직선 스타일, SVG 기반

### 14.3 상태관리

#### 14.3.1 React Query
- 서버 상태 관리
- 캐시 전략
- staleTime 설정

#### 14.3.2 폼 처리
- Zod + react-hook-form
- 유효성 검증
- 에러 메시지

#### 14.3.3 상태 패턴
- 로딩/에러/성공/빈데이터 처리 일관성

### 14.4 디자인 규칙

#### 14.4.1 UI/UX
- 직사각형 레이아웃: 모든 모서리는 90도 각도
- 일관된 여백: 8px 증분 사용
- 모노크롬: 흑백 + 회색 음영만 사용
- 타이포그래피: 제목 24/20/18px, 본문 16/14px
- 반응형 설계: 모바일(320px) - 데스크탑(1920px)
- 대시보드: 모듈식 카드 그리드
- 스켈레톤 UI: 로딩 상태 명확히 표시

#### 14.4.2 접근성 요구사항
- 키보드 내비게이션: 모든 기능 Tab 접근 가능
- 명도 대비(흑/백): 최소 4.5:1 비율 준수
- 포커스 스타일: 시각적 구분 명확화
- ARIA 레이블: 모든 상호작용 요소에 적용

## 15. 백엔드 데이터 스키마 및 API

### 15.1 주요 엔터티

```
users, roles - 사용자 및 권한
analysts - 애널리스트
reports, report_sections - 리포트 및 섹션
companies - 기업
filings - 공시
forecasts - 예측
recommendations - 추천
awards - 어워드
criteria - 평가 기준
scores - 점수
agents - 에이전트
jobs, job_logs - 작업 및 로그
datasets - 데이터셋
vectors - 벡터
```

### 15.2 핵심 스키마 예시

#### 15.2.1 analysts
```sql
id, name, firm, sector, experience_years, profile_url
```

#### 15.2.2 reports
```sql
id, analyst_id, company_id, date, title, source_url,
parsed_json(JSONB), embedding_vector
```

#### 15.2.3 companies
```sql
id, ticker, name_kr, name_en, sector, market_cap,
fundamentals(JSONB)
```

### 15.3 API 엔드포인트

#### 15.3.1 애널리스트 API
- `GET /analysts` - 전체 애널리스트 목록 조회
- `GET /analysts/{id}` - 특정 애널리스트 상세정보

#### 15.3.2 리포트 API
- `GET /reports?analyst=...` - 특정 조건 리포트 검색
- `POST /reports/parse` - 리포트 파싱 작업 요청

#### 15.3.3 어워드 API
- `POST /awards/run` - 어워드 선정 평가 실행

#### 15.3.4 스코어 API
- `POST /scores/recompute` - 스코어 재계산

#### 15.3.5 에이전트 API
- `POST /agents/run` - AI 에이전트 작업 실행
- `WS /jobs/{job_id}/stream` - 작업 실시간 상태 스트림

### 15.4 인증 및 배치 작업

#### 15.4.1 인증
- JWT(Access/Refresh)
- 역할: admin, editor, viewer

#### 15.4.2 배치/큐
- Celery 기반 작업 처리
- 작업 종류:
  - `parse_report` - 리포트 파싱 및 구조화
  - `fetch_company` - 기업 데이터 수집
  - `compute_score` - 애널리스트 성과 점수 계산
  - `run_award` - 어워드 선정 프로세스 실행

### 15.5 검색 기능
- pg_trgm/tsvector: 텍스트 검색
- 벡터검색(pgvector): 유사 문서 조회

### 15.6 마이그레이션
- Alembic 스크립트 생성

## 16. 멀티 LLM 연동 오케스트레이션

### 16.1 환경 설정

**환경변수**:
```
OPENAI_API_KEY
ANTHROPIC_API_KEY
GOOGLE_API_KEY
PERPLEXITY_API_KEY
LLM_BUDGET_DAILY
```

### 16.2 어댑터 패턴

**어댑터 인터페이스**:
- `openai_adapter`
- `anthropic_adapter`
- `gemini_adapter`
- `perplexity_adapter`

**통합 인터페이스**: `generate()`, `embed()`, `tools()`

### 16.3 라우팅 전략

**작업별 최적 LLM 선택**:
- 생성/요약: OpenAI→Claude 폴백
- 장문 컨텍스트: Claude 우선
- 멀티모달: Gemini 우선
- 실시간 검색: Perplexity→OpenAI 리라이트

### 16.4 출력 포맷 및 품질 관리

#### 16.4.1 출력 포맷
- JSON Schema 기반의 strict 모드(함수호출/툴콜 선호)
- 체인오브소트 노출 금지·간단 근거 요약만

#### 16.4.2 비용/안정성
- 레이트리밋, 지수백오프, 재시도 메커니즘
- 캐시(Redis), 결과 해시 검사

#### 16.4.3 샌드박스 테스트
- 관측: 요청/응답/비용 로깅
- 샘플링 기반 품질평가(BLEU/ROUGE/정확도)
- E2E 회귀 테스트

### 16.5 프롬프트 템플릿 레이어

#### 16.5.1 System 프롬프트
- 역할 정의, 규칙, 톤 설정

#### 16.5.2 Task 프롬프트
- 목표, 입력 스키마, 작업 정의

#### 16.5.3 Guard 프롬프트
- 법률/윤리적 가이드, 금칙어

### 16.6 산출물
- 어댑터 코드: 4개 어댑터 모듈
- 통합 Router: 작업 유형별 최적 LLM 선택
- 샘플 워크플로우: YAML 기반 정의
- 재사용 가능한 파이프라인

## 17. AI 에이전트 정의 및 워크플로우

### 17.1 평가 에이전트 (Evaluation Agent)

**목적**: 애널리스트별 정확도/시의성/커버리지 산출 → scores 테이블 업데이트

**입력**: `analyst_id`, `period`, `metrics[]`

**출력**: `{accuracy: float, timeliness: float, coverage: float, composite: float}`

**툴**: DB 쿼리, 통계 라이브러리, 성과 메트릭 계산기

**호출 모델**: OpenAI + Claude 크로스체크(결과 검증)

**엔드포인트**: `POST /agents/evaluation/run`, 매일 23:00 배치 작업

### 17.2 Award 에이전트 (Award Agent)

**목적**: 연간/분기별 카테고리별 후보 선별→근거 생성→우승자 산출

**입력**: `{year: int, quarter?: int, categories: string[]}`

**출력**: `{winners: [{category, analyst_id, evidence}], runners_up: [...]}`

**툴**: 점수 집계기, 순위 알고리즘, 텍스트 근거 생성기

**호출 모델**: Claude(장문 컨텍스트) → OpenAI(검증)

**엔드포인트**: `POST /agents/award/run`, 분기별/연간 스케줄

### 17.3 리포트 생성 에이전트 (Report Generation Agent)

**목적**: 기업/섹터 분석 리포트 자동 생성(요약/차트 지정), JSON 구조 출력

**입력**: `{company_id/sector_id, report_type, depth_level, data_sources: []}`

**출력**: `{sections: [], summary: "", charts: [], recommendations: []}`

**툴**: 차트 생성기, 표 생성기, 코퍼스 검색, 문서 템플릿

**호출 모델**: OpenAI GPT-4 (추론) + Claude (검증)

**엔드포인트**: `POST /agents/report/generate`, 온디맨드

### 17.4 리포트 파싱 에이전트 (Report Parsing Agent)

**목적**: PDF/HTML 파싱→섹션/표 추출→정규화→임베딩 적재

**입력**: `{report_url, report_type, source_format, analyst_id}`

**출력**: `{sections: [], tables: [], entities: [], embedding_vectors: []}`

**툴**: PDF 파서, HTML 추출기, 표 구조화, 벡터 임베딩

**호출 모델**: Gemini(멀티모달) + OpenAI 임베딩

**엔드포인트**: `POST /agents/report/parse`, 업로드시 트리거

### 17.5 기업정보 검증 에이전트 (Company Verification Agent)

**목적**: 공시/포털 대조로 데이터 정합성 검증

**입력**: `{company_id, verification_fields: [], sources: []}`

**출력**: `{verified: bool, discrepancies: [], corrected_data: {}, confidence: float}`

**툴**: 공시 크롤러, 웹 스크래퍼, 데이터 비교기, 규칙 엔진

**호출 모델**: Perplexity(검색) + Claude(판단)

**엔드포인트**: `POST /agents/company/verify`, 매일 08:00 배치

### 17.6 실적 검증 에이전트 (Performance Verification Agent)

**목적**: 예측 vs 실제, 지표별 MAPE/Bias 산출

**입력**: `{analyst_id, company_id, period, metrics: []}`

**출력**: `{mape: float, bias: float, hit_rate: float, metrics_detail: []}`

**툴**: 통계 라이브러리, 예측 평가기, 시계열 비교기

**호출 모델**: OpenAI + Gemini(차트 검증)

**엔드포인트**: `POST /agents/performance/verify`, 분기 실적 발표 후

### 17.7 추천종목 추적 에이전트 (Stock Tracking Agent)

**목적**: 추천 이후 수익률/최대낙폭/샤프지수 추적

**입력**: `{recommendation_id, tracking_period, benchmark_id}`

**출력**: `{returns: float, max_drawdown: float, sharpe: float, benchmark_diff: float}`

**툴**: 시계열 분석기, 성과 계산기, 위험 측정기

**호출 모델**: OpenAI + Perplexity(시장 변동 이슈 검색)

**엔드포인트**: `POST /agents/tracking/calculate`, 매일 시장 종료 후

### 17.8 데이터 수집 에이전트 (Data Collection Agent)

**목적**: 크롤링/스크래핑(robots 준수, 재시도/백오프)

**입력**: `{sources: [], data_types: [], date_range: {}, filters: {}}`

**출력**: `{collected_data: [], stats: {}, errors: [], next_cursor: string}`

**툴**: Playwright, Selenium, RSS 파서, API 클라이언트

**호출 모델**: Gemini(구조 인식) + Perplexity(검증)

**엔드포인트**: `POST /agents/data/collect`, 스케줄링(Airflow)

### 17.9 멀티 LLM 오케스트레이터 (Orchestrator Agent)

**목적**: 작업 분해/라우팅/앙상블/크로스체크

**입력**: `{task: string, context: {}, params: {}, quality_threshold: float}`

**출력**: `{result: {}, confidence: float, models_used: [], reasoning: []}`

**툴**: 작업 분해기, 모델 라우터, 결과 앙상블러, 일관성 검사기

**호출 모델**: 모든 LLM + 자체 라우팅 로직

**엔드포인트**: `POST /agents/orchestrator/run`, 시스템 내부 호출

### 17.10 포트폴리오 분석 에이전트 (Portfolio Analysis Agent)

**목적**: 리밸런싱 제안, 리스크 한도 체크

**입력**: `{portfolio_id, holdings: [], constraints: {}, target_return: float}`

**출력**: `{rebalance_actions: [], risk_metrics: {}, expected_return: float}`

**툴**: 포트폴리오 최적화기, 리스크 분석기, 상관관계 행렬

**호출 모델**: OpenAI(추론) + Claude(검증) + Perplexity(시장 조건)

**엔드포인트**: `POST /agents/portfolio/analyze`, 주간/온디맨드

### 17.11 애널리스트 리포트 AI 에이전트 (Analyst Report Agent)

**목적**: 고성능 PDF 파서로 애널리스트 리포트 구조화 → 표/차트/이미지/텍스트 추출

**입력**: `{report_file: binary, report_type: string, extraction_targets: ["tables", "charts", "text", "formulas"]}`

**출력**: `{structured_content: {}, tables: [], charts: [], images: [], formulas: [], text_blocks: [], metadata: {}}`

**특수 기능**:
- VLM 차트인식
- LLM 보정
- 한/영 인코딩 처리
- 수식 OCR
- 표 구조화
- 이미지 텍스트 추출

**툴**:
- PyMuPDF/PDFPlumber
- OCR(Tesseract+EasyOCR)
- 차트 인식기(Gemini Vision)
- 표 추출기(Tabula)
- 수식 파서(LaTeX)
- 한글 인코딩 컨버터

**호출 모델**: Gemini(멀티모달) + Claude(텍스트 컨텍스트) + OpenAI(구조화) + OCR 엔진

**엔드포인트**: `POST /agents/report/analyze`, 리포트 업로드시 자동 트리거

**파싱 파이프**:
1. 메타데이터 추출
2. VLM 레이아웃 분석
3. 표/이미지/차트 영역 식별
4. OCR 텍스트 추출
5. LLM 보정(오류수정)
6. 구조화

### 17.12 공통 가드레일 및 표준

#### 17.12.1 정책 준수
- 사내 정책/저작권/개인정보 준수
- 출처/근거 필드 포함
- 한국어 기본 출력

#### 17.12.2 입출력 스키마
- JSON Schema 기반으로 엄격하게 유효성 검사

#### 17.12.3 실패 처리
- 모든 에이전트는 실패 처리 로직과 로깅, 비용 추적, 재시도 전략 포함

#### 17.12.4 보안 및 제한
- 레이트리밋 준수
- 결과 캐싱
- 데이터 마스킹 표준 적용

#### 17.12.5 품질 메트릭
- 정확도, 정밀도, 재현율, F1, 응답시간 등 측정

## 18. API 설계

### 18.1 문서 업로드 및 추출 API

```
POST /api/reports/upload
```

**Request**:
- multipart/form-data
- file: PDF 파일
- analyst_id: 애널리스트 ID
- company_id: 기업 ID (optional)
- market_id: 시장 ID (optional)

**Response**:
```json
{
  "report_id": "uuid",
  "status": "processing",
  "estimated_completion_time": "2025-01-16T12:00:00Z"
}
```

### 18.2 추출 상태 조회 API

```
GET /api/reports/{report_id}/extraction-status
```

**Response**:
```json
{
  "report_id": "uuid",
  "status": "processing",
  "progress": {
    "pages_processed": 25,
    "total_pages": 50,
    "percentage": 50
  }
}
```

### 18.3 예측 정보 조회 API

```
GET /api/reports/{report_id}/predictions
```

**Response**:
```json
{
  "report_id": "uuid",
  "predictions": [
    {
      "id": "uuid",
      "prediction_type": "target_price",
      "predicted_value": 50000,
      "unit": "원",
      "period": "2025-06"
    }
  ]
}
```

### 18.4 평가 시작 API

```
POST /api/evaluations/start
```

**Request**:
```json
{
  "report_id": "uuid"
}
```

### 18.5 스코어카드 조회 API

```
GET /api/scorecards
```

**Query Parameters**:
- `analyst_id`: 애널리스트 ID (optional)
- `company_id`: 기업 ID (optional)
- `market_id`: 시장 ID (optional)
- `period`: 기간 (optional)

**Response**:
```json
{
  "scorecards": [
    {
      "id": "uuid",
      "analyst_name": "홍길동",
      "company_name": "삼성전자",
      "final_score": 85.5,
      "ranking": 1,
      "period": "2025-Q1"
    }
  ]
}
```

### 18.6 애널리스트 일괄 등록 API

```
POST /api/analysts/bulk-import
```

**Request**:
- multipart/form-data
- file: Excel 파일

**Response**:
```json
{
  "import_id": "uuid",
  "total_records": 100,
  "success_count": 95,
  "failed_count": 5,
  "failed_records": [
    {
      "row": 10,
      "analyst_name": "홍길동",
      "reason": "중복된 애널리스트"
    }
  ],
  "status": "completed",
  "data_collection_started": true
}
```

### 18.7 데이터 수집 시작 API

```
POST /api/data-collection/start
```

**Request**:
```json
{
  "analyst_id": "uuid",
  "collection_types": ["target_price", "performance", "sns", "media"],
  "start_date": "2025-01-01",
  "end_date": "2025-03-31"
}
```

**Response**:
```json
{
  "collection_job_id": "uuid",
  "status": "started",
  "estimated_completion_time": "2025-01-16T12:00:00Z"
}
```

### 18.8 데이터 수집 상태 조회 API

```
GET /api/data-collection/{collection_job_id}/status
```

**Response**:
```json
{
  "collection_job_id": "uuid",
  "status": "processing",
  "progress": {
    "target_price": {
      "status": "completed",
      "records_collected": 10
    },
    "performance": {
      "status": "processing",
      "records_collected": 5,
      "total_expected": 9
    },
    "sns": {
      "status": "pending"
    },
    "media": {
      "status": "pending"
    }
  },
  "overall_progress": 0.5
}
```

### 18.9 상세 평가보고서 생성 API

```
POST /api/evaluation-reports/generate
```

**Request**:
```json
{
  "evaluation_id": "uuid",
  "include_sections": ["target_price", "performance", "sns", "media"],
  "detail_level": "high"
}
```

**Response**:
```json
{
  "report_id": "uuid",
  "status": "generating",
  "estimated_completion_time": "2025-01-16T12:00:00Z"
}
```

### 18.10 상세 평가보고서 조회 API

```
GET /api/evaluation-reports/{report_id}
```

**Response**:
```json
{
  "report_id": "uuid",
  "evaluation_id": "uuid",
  "analyst_name": "홍길동",
  "company_name": "삼성전자",
  "report_date": "2025-01-16",
  "sections": [...],
  "overall_evaluation": {...},
  "metadata": {
    "data_sources_count": 25,
    "verification_status": "verified",
    "report_quality_score": 0.95,
    "generated_by": ["OpenAI", "Claude", "Gemini", "Perplexity"]
  }
}
```

## 19. 기대효과 및 결론

### 19.1 글로벌 경쟁력 확보
멀티 LLM 기반 AI 애널리스트 어워드는 기술 혁신을 통한 국내 금융 리서치 시장의 글로벌 경쟁력 강화에 기여

### 19.2 투자자 의사결정 혁신
정확한 데이터 분석과 복합추론 능력을 통해 투자자들에게 최적화된 포트폴리오 구성 및 투자 전략 제시

### 19.3 금융 리서치 패러다임 전환
인간 애널리스트와 AI의 협업 모델을 구축하여 리서치의 품질, 속도, 정확성 모두 향상

### 19.4 시장 신뢰도 향상
객관적인 평가 체계와 투명한 데이터 기반 분석으로 애널리스트 평가의 공정성과 신뢰성 제고

### 19.5 미래 로드맵
2026년 파일럿 운영을 시작으로 지속적인 기능 고도화 및 글로벌 스탠더드 AI Investment Award로 발전 추진

## 20. 모니터링 및 로깅

### 20.1 모니터링
- 문서 추출 진행률
- 평가 진행률
- AI API 호출 횟수 및 비용
- 시스템 리소스 사용량

### 20.2 로깅
- 문서 추출 로그
- 예측 정보 추출 로그
- 평가 프로세스 로그
- 에러 로그

## 21. 보안 및 프라이버시

### 21.1 데이터 보호
- PDF 파일 암호화 저장
- 개인정보 암호화
- 데이터베이스 접근 제어

### 21.2 API 보안
- 인증 및 권한 관리
- Rate Limiting
- 입력 검증

