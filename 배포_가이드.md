# 배포 가이드

## 개요

이 가이드는 AI가 찾은 스타 애널리스트 어워즈 시스템의 배포를 위한 포괄적인 가이드입니다.

## 1. 포트 구성 정합성 검토

### 1.1 개발 환경 포트 구성

| 서비스 | 포트 | 환경변수 | 비고 |
|--------|------|----------|------|
| 프론트엔드 (Next.js) | 3000 | 기본값 | `npm run dev` |
| 백엔드 (FastAPI) | 8000 | 기본값 | `uvicorn app.main:app --port 8000` |
| PostgreSQL | 5432 | `DATABASE_URL` | Docker Compose |
| Redis | 6379 | `REDIS_URL` | Docker Compose |

### 1.2 프로덕션 환경 포트 구성

프로덕션 환경에서는 리버스 프록시(Nginx, Traefik 등)를 사용하여 포트를 관리합니다.

**권장 구성**:
- 프론트엔드: 80/443 (HTTP/HTTPS)
- 백엔드: 내부 네트워크 (외부 노출 불필요)
- PostgreSQL: 내부 네트워크
- Redis: 내부 네트워크

### 1.3 환경변수 포트 및 API URL 설정

#### 프론트엔드 API URL 설정

**개발 환경** (`apps/web/.env.local`):
```bash
# 방법 1: 빈 문자열로 설정 (권장) - Next.js rewrites를 통한 프록시 사용
# CORS 문제 없이 동작하며, /api/* 요청이 자동으로 백엔드로 프록시됩니다
NEXT_PUBLIC_API_URL=

# 방법 2: 직접 백엔드 URL 지정 (백엔드 CORS 설정 필요)
# NEXT_PUBLIC_API_URL=http://localhost:8000
```

**프로덕션 환경** (`apps/web/.env.production`):
```bash
# 실제 백엔드 API URL 설정
NEXT_PUBLIC_API_URL=https://api.yourdomain.com
```

**설정 방법 설명**:
- **빈 문자열 (`""`)**: 상대 경로(`/api/*`)를 사용하며, Next.js rewrites가 백엔드로 프록시합니다. 개발 환경에서 CORS 문제를 피할 수 있어 권장합니다.
- **직접 URL 지정**: 백엔드의 CORS 설정이 올바르게 되어 있어야 합니다.

**백엔드** (`.env` 또는 환경변수):
```bash
# 포트는 uvicorn 실행 시 지정하거나 환경변수로 설정
PORT=8000

# 또는 uvicorn 실행 시
uvicorn app.main:app --host 0.0.0.0 --port ${PORT:-8000}
```

**Docker Compose** (`docker-compose.yml`):
```yaml
services:
  api:
    ports:
      - "${API_PORT:-8000}:8000"
  postgres:
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
  redis:
    ports:
      - "${REDIS_PORT:-6379}:6379"
```

### 1.4 CORS 설정

백엔드에서 프론트엔드 도메인을 허용하도록 설정:

```bash
CORS_ORIGINS=https://yourdomain.com,https://www.yourdomain.com
```

또는 `docker-compose.yml`:
```yaml
services:
  api:
    environment:
      CORS_ORIGINS: ${CORS_ORIGINS:-http://localhost:3000}
```

## 2. 데이터베이스 마이그레이션

> **상세 가이드**: 전체 마이그레이션 가이드는 `apps/api/전체_마이그레이션_가이드.md`를 참조하세요.

### 2.1 마이그레이션 실행

#### Docker Compose 사용 시

```bash
# 마이그레이션 실행
docker-compose exec api alembic upgrade head

# 또는 컨테이너 내부에서
docker-compose exec api bash
cd /app
alembic upgrade head
```

#### 로컬 실행 시

```bash
cd apps/api
alembic upgrade head
```

### 2.2 마이그레이션 상태 확인

```bash
# 현재 마이그레이션 버전 확인
alembic current

# 마이그레이션 히스토리 확인
alembic history

# 다음 마이그레이션 확인
alembic show head
```

### 2.3 마이그레이션 롤백

```bash
# 이전 버전으로 롤백
alembic downgrade -1

# 특정 버전으로 롤백
alembic downgrade <revision>
```

### 2.4 새 마이그레이션 생성

```bash
# 자동 마이그레이션 생성
alembic revision --autogenerate -m "설명"

# 수동 마이그레이션 생성
alembic revision -m "설명"
```

### 2.5 데이터베이스 스키마 구조

시스템은 총 **18개 테이블**로 구성되어 있습니다:

- **기본 엔티티**: analysts, companies, markets
- **리포트 관련**: reports, report_sections, extracted_texts, extracted_tables, extracted_images
- **예측 및 결과**: predictions, actual_results
- **평가 관련**: evaluations, evaluation_scores, evaluation_reports
- **스코어카드 및 수상**: scorecards, awards
- **데이터 수집**: data_sources, data_collection_logs, collection_jobs
- **템플릿**: prompt_templates

상세 스키마 정보는 `apps/api/전체_마이그레이션_가이드.md`를 참조하세요.

## 3. 기초 데이터 생성

### 3.1 데이터베이스 초기화

새로운 데이터베이스를 처음 설정할 때는 테이블을 생성해야 합니다:

```bash
# 로컬 실행
cd apps/api
python scripts/init_db.py

# Docker Compose 사용 시
docker-compose exec api python scripts/init_db.py
```

> **주의**: `init_db.py`는 Alembic 마이그레이션을 사용하지 않고 직접 테이블을 생성합니다. 
> 프로덕션 환경에서는 **반드시 Alembic 마이그레이션을 사용**하세요.

### 3.2 애널리스트 엑셀 데이터 로드

실제 애널리스트 데이터를 엑셀 파일에서 로드할 수 있습니다:

```bash
# 로컬 실행
cd apps/api
python scripts/load_analysts_from_excel.py

# Docker Compose 사용 시
docker-compose exec api python scripts/load_analysts_from_excel.py
```

**엑셀 파일 위치**: `old_assets/증권사 리서치센터 애널리스트 리스트(반도체 자동차 방산 금융 최종) (1).xlsx`

**스크립트 동작**:
- Excel 파일의 모든 시트를 읽습니다
- 이름과 증권사명이 필수입니다
- 중복 체크 후 등록합니다
- 섹터는 시트명 또는 컬럼에서 자동 추출됩니다

**지원하는 컬럼명**:
- 이름: '이름', '애널리스트명', '애널리스트', '애널리스트 이름'
- 증권사: '증권사', '증권사명', '회사', '리서치센터'
- 부서: '부서', '소속부서', '세부 섹터'
- 섹터: '섹터', '업종', '담당 산업'
- 이메일: '이메일', 'Email', 'E-mail'

## 4. 샘플 데이터 생성

### 4.1 샘플 데이터 생성 스크립트

`apps/api/scripts/generate_sample_data.py` 스크립트를 사용하여 테스트용 샘플 데이터를 생성할 수 있습니다:

```python
"""
샘플 데이터 생성 스크립트
"""
import sys
from pathlib import Path

# 프로젝트 루트를 Python 경로에 추가
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from sqlalchemy.orm import Session
from app.database import SessionLocal
from app.models.analyst import Analyst
from app.models.company import Company
from app.models.report import Report
from app.models.evaluation import Evaluation
from app.models.scorecard import Scorecard
from app.models.award import Award
from uuid import uuid4
from datetime import datetime, date, timedelta
from decimal import Decimal

def create_sample_data():
    db: Session = SessionLocal()
    
    try:
        # 샘플 애널리스트 생성
        analysts = []
        firms = ["삼성증권", "KB증권", "미래에셋증권", "NH투자증권", "한국투자증권"]
        sectors = ["반도체", "자동차", "방산", "금융", "바이오"]
        
        for i in range(10):
            analyst = Analyst(
                id=uuid4(),
                name=f"애널리스트 {i+1}",
                firm=firms[i % len(firms)],
                department="리서치센터",
                sector=sectors[i % len(sectors)],
                experience_years=5 + (i % 10),
                email=f"analyst{i+1}@example.com"
            )
            db.add(analyst)
            analysts.append(analyst)
        
        db.commit()
        print(f"✅ {len(analysts)}명의 애널리스트 생성 완료")
        
        # 샘플 기업 생성
        companies = []
        company_names = [
            ("삼성전자", "005930"),
            ("SK하이닉스", "000660"),
            ("현대자동차", "005380"),
            ("LG전자", "066570"),
            ("NAVER", "035420")
        ]
        
        for name_kr, ticker in company_names:
            company = Company(
                id=uuid4(),
                ticker=ticker,
                name_kr=name_kr,
                name_en=name_kr,
                sector="IT",
                market_cap=Decimal("1000000000000")
            )
            db.add(company)
            companies.append(company)
        
        db.commit()
        print(f"✅ {len(companies)}개의 기업 생성 완료")
        
        # 샘플 리포트 생성
        reports = []
        for i in range(20):
            report = Report(
                id=uuid4(),
                analyst_id=analysts[i % len(analysts)].id,
                company_id=companies[i % len(companies)].id if i % 2 == 0 else None,
                title=f"리포트 제목 {i+1}",
                publication_date=date.today() - timedelta(days=i),
                status="completed"
            )
            db.add(report)
            reports.append(report)
        
        db.commit()
        print(f"✅ {len(reports)}개의 리포트 생성 완료")
        
        # 샘플 평가 생성
        evaluations = []
        for i, report in enumerate(reports[:10]):
            evaluation = Evaluation(
                id=uuid4(),
                report_id=report.id,
                analyst_id=report.analyst_id,
                company_id=report.company_id,
                evaluation_period=f"2025-Q{(i % 4) + 1}",
                evaluation_date=date.today() - timedelta(days=i),
                final_score=Decimal("75.5") + Decimal(str(i)),
                status="completed"
            )
            db.add(evaluation)
            evaluations.append(evaluation)
        
        db.commit()
        print(f"✅ {len(evaluations)}개의 평가 생성 완료")
        
        # 샘플 스코어카드 생성
        scorecards = []
        for i, evaluation in enumerate(evaluations):
            scorecard = Scorecard(
                id=uuid4(),
                analyst_id=evaluation.analyst_id,
                company_id=evaluation.company_id,
                period=evaluation.evaluation_period,
                final_score=evaluation.final_score,
                ranking=i+1,
                scorecard_data={
                    "evaluation_id": str(evaluation.id),
                    "scores": {
                        "accuracy": 80.0 + i,
                        "timeliness": 75.0 + i,
                        "coverage": 70.0 + i
                    }
                }
            )
            db.add(scorecard)
            scorecards.append(scorecard)
        
        db.commit()
        print(f"✅ {len(scorecards)}개의 스코어카드 생성 완료")
        
        # 샘플 어워드 생성
        awards = []
        award_types = ["gold", "silver", "bronze"]
        categories = ["반도체", "자동차", "방산", "금융", "바이오"]
        
        for i in range(15):
            award = Award(
                id=uuid4(),
                analyst_id=analysts[i % len(analysts)].id,
                award_type=award_types[i % len(award_types)],
                award_category=categories[i % len(categories)],
                period="2025-Q1",
                rank=i+1
            )
            db.add(award)
            awards.append(award)
        
        db.commit()
        print(f"✅ {len(awards)}개의 어워드 생성 완료")
        
        print("\n🎉 샘플 데이터 생성 완료!")
        print(f"  - 애널리스트: {len(analysts)}명")
        print(f"  - 기업: {len(companies)}개")
        print(f"  - 리포트: {len(reports)}개")
        print(f"  - 평가: {len(evaluations)}개")
        print(f"  - 스코어카드: {len(scorecards)}개")
        print(f"  - 어워드: {len(awards)}개")
        
    except Exception as e:
        db.rollback()
        print(f"❌ 오류 발생: {e}")
        raise
    finally:
        db.close()

if __name__ == "__main__":
    create_sample_data()
```

### 4.2 샘플 데이터 생성 실행

```bash
# 로컬 실행
cd apps/api
python scripts/generate_sample_data.py

# Docker Compose 사용 시
docker-compose exec api python scripts/generate_sample_data.py
```

**생성되는 데이터**:
- 애널리스트: 10명
- 기업: 5개 (삼성전자, SK하이닉스, 현대자동차, LG전자, NAVER)
- 리포트: 20개
- 평가: 10개
- 스코어카드: 10개
- 어워드: 15개

> **참고**: 샘플 데이터는 테스트 및 개발 목적으로만 사용하세요. 
> 프로덕션 환경에서는 실제 데이터를 사용하거나 애널리스트 엑셀 데이터를 로드하세요.

## 5. 배포 단계별 가이드

### 5.1 개발 환경 배포

#### 1단계: 환경 변수 설정

```bash
# 프론트엔드
cd apps/web
# .env.local 파일 생성
cat > .env.local << EOF
# API URL 설정 (빈 문자열 권장 - Next.js rewrites 사용)
NEXT_PUBLIC_API_URL=

# 서버 사이드에서 사용할 백엔드 URL (Next.js rewrites용)
API_URL=http://localhost:8000
EOF

# 또는 직접 편집
# NEXT_PUBLIC_API_URL= 빈 문자열로 설정하면 상대 경로 사용
# NEXT_PUBLIC_API_URL=http://localhost:8000 직접 URL 지정 (CORS 설정 필요)

# 백엔드
cp .env.example .env
# .env 파일 편집
# DATABASE_URL, REDIS_URL, API 키 등 설정
```

#### 2단계: 의존성 설치

```bash
# 프론트엔드
cd apps/web
npm install

# 백엔드
cd apps/api
pip install -r requirements.txt
```

#### 3단계: 데이터베이스 마이그레이션

```bash
cd apps/api
alembic upgrade head
```

#### 4단계: 기초 데이터 생성 (선택)

```bash
# 애널리스트 엑셀 데이터 로드 (실제 데이터)
cd apps/api
python scripts/load_analysts_from_excel.py

# 또는 샘플 데이터 생성 (테스트용)
python scripts/generate_sample_data.py
```

#### 5단계: 서비스 시작

```bash
# Docker Compose 사용
docker-compose up -d

# 또는 개별 실행
# 터미널 1: 백엔드
cd apps/api
uvicorn app.main:app --reload --port 8000

# 터미널 2: Celery Worker
cd apps/api
celery -A app.celery_app worker --loglevel=info

# 터미널 3: 프론트엔드
cd apps/web
npm run dev
```

### 5.2 프로덕션 환경 배포

#### 1단계: 빌드

```bash
# 프론트엔드 빌드
cd apps/web
npm run build

# 백엔드는 런타임에 실행되므로 빌드 불필요
```

#### 2단계: 환경 변수 설정

프로덕션 환경변수를 설정합니다 (환경변수 관리 도구 사용 권장).

**필수 환경변수**:
- `DATABASE_URL`: PostgreSQL 연결 문자열
- `REDIS_URL`: Redis 연결 문자열
- `NEXT_PUBLIC_API_URL`: 프론트엔드에서 사용할 API URL
- `PERPLEXITY_API_KEY`: Perplexity API 키 (데이터 수집용)
- `OPENAI_API_KEY`: OpenAI API 키 (평가용)
- `CORS_ORIGINS`: 허용할 프론트엔드 도메인

#### 3단계: 데이터베이스 마이그레이션

```bash
# 프로덕션 데이터베이스에 마이그레이션 실행
cd apps/api
alembic upgrade head

# 마이그레이션 상태 확인
alembic current
```

#### 4단계: 기초 데이터 생성

```bash
# 애널리스트 엑셀 데이터 로드 (실제 운영 데이터)
cd apps/api
python scripts/load_analysts_from_excel.py

# 주의: 샘플 데이터는 프로덕션에서 사용하지 마세요
```

#### 5단계: 서비스 시작

```bash
# Docker Compose 사용
docker-compose -f docker-compose.prod.yml up -d

# 또는 PM2, systemd 등으로 관리
```

## 6. 배포 체크리스트

### 6.1 사전 배포 체크리스트

- [ ] 환경 변수 설정 완료
- [ ] 데이터베이스 연결 확인
- [ ] Redis 연결 확인
- [ ] API 키 설정 확인 (Perplexity, OpenAI 등)
- [ ] CORS 설정 확인
- [ ] 포트 충돌 확인

### 6.2 배포 중 체크리스트

- [ ] 데이터베이스 마이그레이션 실행 (`alembic upgrade head`)
- [ ] 마이그레이션 상태 확인 (`alembic current`)
- [ ] 기초 데이터 생성 (애널리스트 엑셀 로드 또는 샘플 데이터)
- [ ] 백엔드 서버 시작
- [ ] Celery Worker 시작
- [ ] 프론트엔드 빌드 (프로덕션)
- [ ] 프론트엔드 서버 시작

### 6.3 배포 후 체크리스트

- [ ] Health Check API 응답 확인 (`/api/health`)
- [ ] 프론트엔드 페이지 로드 확인
- [ ] API 엔드포인트 동작 확인
- [ ] 데이터베이스 연결 확인
- [ ] Redis 연결 확인
- [ ] 로그 확인
- [ ] 애널리스트 데이터 확인
- [ ] 샘플 데이터 생성 (개발 환경만)

## 7. 문제 해결

### 7.1 포트 충돌

```bash
# 포트 사용 확인
lsof -i :8000  # macOS/Linux
netstat -ano | findstr :8000  # Windows

# 다른 포트 사용
uvicorn app.main:app --port 8001
```

### 7.2 데이터베이스 연결 실패

```bash
# 연결 테스트
psql -h localhost -U user -d analyst_awards

# 환경변수 확인
echo $DATABASE_URL
```

### 7.3 CORS 오류

**해결 방법 1: 프론트엔드에서 상대 경로 사용 (권장)**

프론트엔드 `.env.local`에서:
```bash
NEXT_PUBLIC_API_URL=
```

이렇게 설정하면 Next.js rewrites가 자동으로 프록시하므로 CORS 문제가 발생하지 않습니다.

**해결 방법 2: 백엔드 CORS 설정**

백엔드 `CORS_ORIGINS` 환경변수에 프론트엔드 도메인 추가:

```bash
CORS_ORIGINS=http://localhost:3000,https://yourdomain.com
```

또는 `docker-compose.yml`:
```yaml
services:
  api:
    environment:
      CORS_ORIGINS: ${CORS_ORIGINS:-http://localhost:3000}
```

### 7.4 엑셀 업로드 오류 (Redis/Celery 연결 실패)

**증상**:
- `Error 99 connecting to localhost:6379. Cannot assign requested address`
- `Internal server error` 발생
- 엑셀 파일 업로드는 성공하지만 데이터 수집 자동 시작 실패

**원인**:
- 엑셀 업로드 후 자동으로 데이터 수집을 시작하기 위해 Celery 비동기 작업 호출
- Celery는 Redis를 메시지 브로커로 사용
- Redis가 설치/실행되지 않은 환경에서 연결 실패

**해결 방법**:

1. **Redis 설치 및 실행 (선택사항)**:
```bash
# Docker Compose 사용 시
docker-compose up -d redis

# 로컬 설치 (macOS)
brew install redis
brew services start redis

# 로컬 설치 (Linux)
sudo apt-get install redis-server
sudo systemctl start redis
```

2. **Redis 없이 사용 (권장 - 개발 환경)**:
- 현재 코드는 Redis가 없어도 애널리스트 등록은 정상 동작합니다
- 데이터 수집은 나중에 수동으로 시작할 수 있습니다
- 에러는 로그에만 기록되고 애널리스트 등록은 성공합니다

**참고**:
- Redis/Celery는 비동기 작업(데이터 수집)에만 사용됩니다
- 애널리스트 등록 자체는 Redis 없이도 정상 동작합니다
- 프로덕션 환경에서는 Redis 사용을 권장합니다

### 7.5 API 호출 오류 (Network Error, CORS)

**증상**:
- `API Request Error: No response received`
- `Network Error`
- `baseURL: "http://localhost:8000"`

**원인**:
- `NEXT_PUBLIC_API_URL`이 설정되지 않아 fallback으로 `http://localhost:8000` 사용
- 브라우저에서 직접 다른 포트로 요청 시 CORS 문제 발생

**해결 방법**:

1. **프론트엔드 `.env.local` 파일 생성/수정**:
```bash
cd apps/web
cat > .env.local << EOF
# 빈 문자열로 설정 (권장) - Next.js rewrites 사용
NEXT_PUBLIC_API_URL=

# 서버 사이드 프록시용 백엔드 URL
API_URL=http://localhost:8000
EOF
```

2. **Next.js 개발 서버 재시작**:
```bash
# 환경변수 변경 후 반드시 재시작 필요
npm run dev
```

3. **확인**:
- 브라우저 콘솔에서 `baseURL`이 빈 문자열이거나 상대 경로인지 확인
- Network 탭에서 요청이 `/api/*`로 가는지 확인

### 7.6 마이그레이션 오류

```bash
# 마이그레이션 상태 확인
cd apps/api
alembic current

# 마이그레이션 히스토리 확인
alembic history

# 특정 버전으로 롤백
alembic downgrade -1

# 전체 마이그레이션 가이드 참조
# apps/api/전체_마이그레이션_가이드.md
```

## 8. 모니터링

### 8.1 로그 확인

```bash
# Docker Compose 로그
docker-compose logs -f api

# 백엔드 로그
tail -f logs/api.log

# Celery 로그
tail -f logs/celery.log
```

### 8.2 헬스 체크

```bash
# API 헬스 체크
curl http://localhost:8000/api/health

# 데이터베이스 연결 확인
curl http://localhost:8000/api/health/db
```

## 9. 롤백 절차

### 9.1 마이그레이션 롤백

```bash
cd apps/api
alembic downgrade -1
```

### 9.2 코드 롤백

```bash
git checkout <previous-commit>
docker-compose restart api
```

## 10. 보안 체크리스트

- [ ] API 키가 환경변수로 관리됨
- [ ] 데이터베이스 비밀번호 강력함
- [ ] CORS 설정이 적절함
- [ ] HTTPS 사용 (프로덕션)
- [ ] 환경변수 파일이 Git에 커밋되지 않음
- [ ] `.env` 파일이 `.gitignore`에 포함됨

## 11. 배포 순서 요약

### 개발 환경

1. 환경 변수 설정
2. 의존성 설치
3. 데이터베이스 마이그레이션 (`alembic upgrade head`)
4. 기초 데이터 생성 (선택: 엑셀 로드 또는 샘플 데이터)
5. 서비스 시작

### 프로덕션 환경

1. 환경 변수 설정
2. 프론트엔드 빌드 (`npm run build`)
3. 데이터베이스 마이그레이션 (`alembic upgrade head`)
4. 기초 데이터 생성 (애널리스트 엑셀 로드)
5. 서비스 시작

> **중요**: 프로덕션에서는 반드시 실제 데이터를 사용하고, 샘플 데이터는 사용하지 마세요.

